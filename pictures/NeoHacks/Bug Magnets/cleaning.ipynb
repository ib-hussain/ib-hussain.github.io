{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd942d31",
   "metadata": {},
   "source": [
    "## All files Null columns dropping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "564a1c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from csv/mutations.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ibrahim\\AppData\\Local\\Temp\\ipykernel_8784\\311224176.py:11: DtypeWarning: Columns (50,146,196) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data shape: (13180, 345)\n",
      "Original columns: 345\n",
      "\n",
      "Columns with 100% missing values: 20\n",
      "Columns to be dropped:\n",
      "  - Match_Norm_Seq_Allele1\n",
      "  - Match_Norm_Seq_Allele2\n",
      "  - Tumor_Validation_Allele1\n",
      "  - Tumor_Validation_Allele2\n",
      "  - Match_Norm_Validation_Allele1\n",
      "  - Match_Norm_Validation_Allele2\n",
      "  - Score\n",
      "  - BAM_file\n",
      "  - i_1000gp3_CS\n",
      "  - i_1000gp3_END\n",
      "  - i_1000gp3_MC\n",
      "  - i_1000gp3_MEND\n",
      "  - i_1000gp3_MLEN\n",
      "  - i_1000gp3_MSTART\n",
      "  - i_1000gp3_SVLEN\n",
      "  - i_1000gp3_SVTYPE\n",
      "  - i_1000gp3_TSD\n",
      "  - i_ESP_GWAS_PUBMED\n",
      "  - i_HGNC_Primary IDs\n",
      "  - i_HGNC_Secondary IDs\n",
      "\n",
      "Cleaned data shape: (13180, 325)\n",
      "Remaining columns: 325\n",
      "\n",
      "Cleaned dataset saved to: csv/mutations.csv\n",
      "\n",
      "Remaining columns with some missing values: 279\n",
      "  - dbSNP_RS: 86.57% missing\n",
      "  - dbSNP_Val_Status: 96.92% missing\n",
      "  - Annotation_Transcript: 0.14% missing\n",
      "  - Transcript_Strand: 0.14% missing\n",
      "  - Transcript_Exon: 0.14% missing\n",
      "  - Transcript_Position: 0.14% missing\n",
      "  - cDNA_Change: 2.85% missing\n",
      "  - Codon_Change: 1.63% missing\n",
      "  - Protein_Change: 2.85% missing\n",
      "  - Other_Transcripts: 19.17% missing\n",
      "  - Refseq_mRNA_Id: 15.96% missing\n",
      "  - Refseq_prot_Id: 15.97% missing\n",
      "  - SwissProt_acc_Id: 2.47% missing\n",
      "  - SwissProt_entry_Id: 2.47% missing\n",
      "  - Description: 0.78% missing\n",
      "  - UniProt_AApos: 5.12% missing\n",
      "  - UniProt_Region: 71.26% missing\n",
      "  - UniProt_Site: 99.99% missing\n",
      "  - UniProt_Natural_Variations: 98.60% missing\n",
      "  - UniProt_Experimental_Info: 99.61% missing\n",
      "  - GO_Biological_Process: 19.85% missing\n",
      "  - GO_Cellular_Component: 10.58% missing\n",
      "  - GO_Molecular_Function: 23.09% missing\n",
      "  - COSMIC_overlapping_mutations: 92.44% missing\n",
      "  - COSMIC_fusion_genes: 98.88% missing\n",
      "  - COSMIC_tissue_types_affected: 3.78% missing\n",
      "  - COSMIC_total_alterations_in_gene: 3.78% missing\n",
      "  - Tumorscape_Amplification_Peaks: 77.00% missing\n",
      "  - Tumorscape_Deletion_Peaks: 69.58% missing\n",
      "  - TCGAscape_Amplification_Peaks: 81.56% missing\n",
      "  - TCGAscape_Deletion_Peaks: 67.84% missing\n",
      "  - DrugBank: 90.10% missing\n",
      "  - CCLE_ONCOMAP_overlapping_mutations: 99.83% missing\n",
      "  - CCLE_ONCOMAP_total_mutations_in_gene: 99.06% missing\n",
      "  - CGC_Mutation_Type: 96.16% missing\n",
      "  - CGC_Translocation_Partner: 98.04% missing\n",
      "  - CGC_Tumor_Types_Somatic: 96.37% missing\n",
      "  - CGC_Tumor_Types_Germline: 98.92% missing\n",
      "  - CGC_Other_Diseases: 99.68% missing\n",
      "  - DNARepairGenes_Role: 98.73% missing\n",
      "  - FamilialCancerDatabase_Syndromes: 97.77% missing\n",
      "  - MUTSIG_Published_Results: 96.38% missing\n",
      "  - OREGANNO_ID: 98.83% missing\n",
      "  - OREGANNO_Values: 98.83% missing\n",
      "  - i_1000gp3_AA: 96.13% missing\n",
      "  - i_1000gp3_AC: 96.09% missing\n",
      "  - i_1000gp3_AF: 96.09% missing\n",
      "  - i_1000gp3_AFR_AF: 96.09% missing\n",
      "  - i_1000gp3_AMR_AF: 96.09% missing\n",
      "  - i_1000gp3_AN: 96.09% missing\n",
      "  - i_1000gp3_CIEND: 96.09% missing\n",
      "  - i_1000gp3_CIPOS: 96.09% missing\n",
      "  - i_1000gp3_DP: 96.09% missing\n",
      "  - i_1000gp3_EAS_AF: 96.09% missing\n",
      "  - i_1000gp3_EUR_AF: 96.09% missing\n",
      "  - i_1000gp3_IMPRECISE: 96.09% missing\n",
      "  - i_1000gp3_MEINFO: 96.09% missing\n",
      "  - i_1000gp3_NS: 96.09% missing\n",
      "  - i_1000gp3_SAS_AF: 96.09% missing\n",
      "  - i_ACHILLES_Lineage_Results_Top_Genes: 92.24% missing\n",
      "  - i_CCLE_ONCOMAP_overlapping_mutations: 99.83% missing\n",
      "  - i_CCLE_ONCOMAP_total_mutations_in_gene: 99.06% missing\n",
      "  - i_CGC_Cancer Germline Mut: 98.92% missing\n",
      "  - i_CGC_Cancer Molecular Genetics: 96.16% missing\n",
      "  - i_CGC_Cancer Somatic Mut: 96.37% missing\n",
      "  - i_CGC_Cancer Syndrome: 98.95% missing\n",
      "  - i_CGC_Chr: 96.16% missing\n",
      "  - i_CGC_Chr Band: 96.16% missing\n",
      "  - i_CGC_GeneID: 96.16% missing\n",
      "  - i_CGC_Mutation_Type: 96.28% missing\n",
      "  - i_CGC_Name: 96.16% missing\n",
      "  - i_CGC_Other Germline Mut: 99.69% missing\n",
      "  - i_CGC_Other_Diseases: 99.74% missing\n",
      "  - i_CGC_Tissue Type: 96.18% missing\n",
      "  - i_CGC_Translocation_Partner: 98.13% missing\n",
      "  - i_CGC_Tumor_Types_Germline: 98.93% missing\n",
      "  - i_CGC_Tumor_Types_Somatic: 96.51% missing\n",
      "  - i_COSMIC_fusion_genes: 99.54% missing\n",
      "  - i_COSMIC_overlapping_mutation_descriptions: 92.44% missing\n",
      "  - i_COSMIC_overlapping_mutations: 98.07% missing\n",
      "  - i_COSMIC_overlapping_primary_sites: 92.44% missing\n",
      "  - i_COSMIC_tissue_types_affected: 21.06% missing\n",
      "  - i_ClinVar_ASSEMBLY: 99.29% missing\n",
      "  - i_ClinVar_HGMD_ID: 99.29% missing\n",
      "  - i_ClinVar_SYM: 99.29% missing\n",
      "  - i_ClinVar_TYPE: 99.29% missing\n",
      "  - i_ClinVar_rs: 99.68% missing\n",
      "  - i_DNARepairGenes_Role: 98.68% missing\n",
      "  - i_DrugBank: 92.07% missing\n",
      "  - i_ESP_AA: 94.95% missing\n",
      "  - i_ESP_AAC: 95.96% missing\n",
      "  - i_ESP_AA_AC: 94.64% missing\n",
      "  - i_ESP_AA_AGE: 98.03% missing\n",
      "  - i_ESP_AA_GTC: 94.64% missing\n",
      "  - i_ESP_AvgAAsampleReadDepth: 4.45% missing\n",
      "  - i_ESP_AvgEAsampleReadDepth: 4.45% missing\n",
      "  - i_ESP_AvgSampleReadDepth: 4.45% missing\n",
      "  - i_ESP_CA: 99.95% missing\n",
      "  - i_ESP_CDP: 94.83% missing\n",
      "  - i_ESP_CG: 94.64% missing\n",
      "  - i_ESP_CP: 94.64% missing\n",
      "  - i_ESP_Chromosome: 4.45% missing\n",
      "  - i_ESP_DBSNP: 97.53% missing\n",
      "  - i_ESP_DP: 94.64% missing\n",
      "  - i_ESP_EA_AC: 94.64% missing\n",
      "  - i_ESP_EA_AGE: 97.59% missing\n",
      "  - i_ESP_EA_GTC: 94.64% missing\n",
      "  - i_ESP_EXOME_CHIP: 94.64% missing\n",
      "  - i_ESP_FG: 94.64% missing\n",
      "  - i_ESP_GL: 94.66% missing\n",
      "  - i_ESP_GM: 94.66% missing\n",
      "  - i_ESP_GS: 96.00% missing\n",
      "  - i_ESP_GTC: 94.64% missing\n",
      "  - i_ESP_GTS: 94.64% missing\n",
      "  - i_ESP_MAF: 94.64% missing\n",
      "  - i_ESP_PH: 96.02% missing\n",
      "  - i_ESP_PP: 94.83% missing\n",
      "  - i_ESP_Position: 4.45% missing\n",
      "  - i_ESP_TAC: 94.64% missing\n",
      "  - i_ESP_TotalAAsamplesCovered: 4.45% missing\n",
      "  - i_ESP_TotalEAsamplesCovered: 4.45% missing\n",
      "  - i_ESP_TotalSamplesCovered: 4.45% missing\n",
      "  - i_Ensembl_so_accession: 0.44% missing\n",
      "  - i_Ensembl_so_term: 0.44% missing\n",
      "  - i_FamilialCancerDatabase_Syndromes: 97.21% missing\n",
      "  - i_Familial_Cancer_Genes_Reference: 97.77% missing\n",
      "  - i_Familial_Cancer_Genes_Synonym: 97.92% missing\n",
      "  - i_GO_Biological_Process: 27.97% missing\n",
      "  - i_GO_Cellular_Component: 14.70% missing\n",
      "  - i_GO_Molecular_Function: 18.10% missing\n",
      "  - i_HGNC_Accession Numbers: 14.07% missing\n",
      "  - i_HGNC_CCDS IDs: 2.27% missing\n",
      "  - i_HGNC_Chromosome: 0.78% missing\n",
      "  - i_HGNC_Date Modified: 0.78% missing\n",
      "  - i_HGNC_Date Name Changed: 55.03% missing\n",
      "  - i_HGNC_Date Symbol Changed: 79.57% missing\n",
      "  - i_HGNC_Ensembl Gene ID: 13.00% missing\n",
      "  - i_HGNC_Ensembl ID(supplied by Ensembl): 2.75% missing\n",
      "  - i_HGNC_Enzyme IDs: 93.10% missing\n",
      "  - i_HGNC_Gene family description: 43.36% missing\n",
      "  - i_HGNC_HGNC ID: 0.78% missing\n",
      "  - i_HGNC_Locus Group: 0.78% missing\n",
      "  - i_HGNC_Locus Type: 0.78% missing\n",
      "  - i_HGNC_Name Synonyms: 72.10% missing\n",
      "  - i_HGNC_OMIM ID(supplied by NCBI): 20.51% missing\n",
      "  - i_HGNC_Previous Names: 56.29% missing\n",
      "  - i_HGNC_Previous Symbols: 65.55% missing\n",
      "  - i_HGNC_Pubmed IDs: 18.17% missing\n",
      "  - i_HGNC_Record Type: 0.78% missing\n",
      "  - i_HGNC_RefSeq(supplied by NCBI): 0.79% missing\n",
      "  - i_HGNC_Status: 0.78% missing\n",
      "  - i_HGNC_Synonyms: 18.25% missing\n",
      "  - i_HGNC_UCSC ID(supplied by UCSC): 2.61% missing\n",
      "  - i_HGNC_UniProt ID(supplied by UniProt): 0.80% missing\n",
      "  - i_HGNC_VEGA IDs: 13.98% missing\n",
      "  - i_HGVS_coding_DNA_change: 1.15% missing\n",
      "  - i_HGVS_protein_change: 29.37% missing\n",
      "  - i_MUTSIG_Published_Results: 96.28% missing\n",
      "  - i_OREGANNO_ID: 98.83% missing\n",
      "  - i_OREGANNO_Values: 98.83% missing\n",
      "  - i_ORegAnno_bin: 98.83% missing\n",
      "  - i_Other_Transcripts: 22.82% missing\n",
      "  - i_Protein_Change: 0.05% missing\n",
      "  - i_Refseq_mRNA_Id: 0.33% missing\n",
      "  - i_Refseq_prot_Id: 0.35% missing\n",
      "  - i_SwissProt_acc_Id: 0.62% missing\n",
      "  - i_SwissProt_entry_Id: 0.62% missing\n",
      "  - i_TCGAscape_Amplification_Peaks: 80.83% missing\n",
      "  - i_TCGAscape_Deletion_Peaks: 66.30% missing\n",
      "  - i_Transcript_Position: 0.01% missing\n",
      "  - i_Tumorscape_Amplification_Peaks: 75.88% missing\n",
      "  - i_Tumorscape_Deletion_Peaks: 68.16% missing\n",
      "  - i_UniProt_AApos: 1.91% missing\n",
      "  - i_UniProt_Experimental_Info: 99.48% missing\n",
      "  - i_UniProt_Natural_Variations: 99.01% missing\n",
      "  - i_UniProt_Region: 48.87% missing\n",
      "  - i_UniProt_Site: 99.88% missing\n",
      "  - i_UniProt_alt_uniprot_accessions: 7.22% missing\n",
      "  - i_annotation_transcript: 0.14% missing\n",
      "  - i_ccds_id: 6.49% missing\n",
      "  - i_dbNSFP_1000Gp1_AC: 29.75% missing\n",
      "  - i_dbNSFP_1000Gp1_AF: 29.75% missing\n",
      "  - i_dbNSFP_1000Gp1_AFR_AC: 29.75% missing\n",
      "  - i_dbNSFP_1000Gp1_AFR_AF: 29.75% missing\n",
      "  - i_dbNSFP_1000Gp1_AMR_AC: 29.75% missing\n",
      "  - i_dbNSFP_1000Gp1_AMR_AF: 29.75% missing\n",
      "  - i_dbNSFP_1000Gp1_ASN_AC: 29.75% missing\n",
      "  - i_dbNSFP_1000Gp1_ASN_AF: 29.75% missing\n",
      "  - i_dbNSFP_1000Gp1_EUR_AC: 29.75% missing\n",
      "  - i_dbNSFP_1000Gp1_EUR_AF: 29.75% missing\n",
      "  - i_dbNSFP_Ancestral_allele: 29.75% missing\n",
      "  - i_dbNSFP_CADD_phred: 29.75% missing\n",
      "  - i_dbNSFP_CADD_raw: 29.75% missing\n",
      "  - i_dbNSFP_CADD_raw_rankscore: 29.75% missing\n",
      "  - i_dbNSFP_ESP6500_AA_AF: 29.75% missing\n",
      "  - i_dbNSFP_ESP6500_EA_AF: 29.75% missing\n",
      "  - i_dbNSFP_Ensembl_geneid: 29.75% missing\n",
      "  - i_dbNSFP_Ensembl_transcriptid: 29.75% missing\n",
      "  - i_dbNSFP_FATHMM_pred: 29.75% missing\n",
      "  - i_dbNSFP_FATHMM_rankscore: 29.75% missing\n",
      "  - i_dbNSFP_FATHMM_score: 29.75% missing\n",
      "  - i_dbNSFP_GERP++_NR: 29.75% missing\n",
      "  - i_dbNSFP_GERP++_RS: 29.75% missing\n",
      "  - i_dbNSFP_GERP++_RS_rankscore: 29.75% missing\n",
      "  - i_dbNSFP_Interpro_domain: 29.75% missing\n",
      "  - i_dbNSFP_LRT_Omega: 29.75% missing\n",
      "  - i_dbNSFP_LRT_converted_rankscore: 29.75% missing\n",
      "  - i_dbNSFP_LRT_pred: 29.75% missing\n",
      "  - i_dbNSFP_LRT_score: 29.75% missing\n",
      "  - i_dbNSFP_LR_pred: 29.75% missing\n",
      "  - i_dbNSFP_LR_rankscore: 29.75% missing\n",
      "  - i_dbNSFP_LR_score: 29.75% missing\n",
      "  - i_dbNSFP_MutationAssessor_pred: 29.75% missing\n",
      "  - i_dbNSFP_MutationAssessor_rankscore: 29.75% missing\n",
      "  - i_dbNSFP_MutationAssessor_score: 29.75% missing\n",
      "  - i_dbNSFP_MutationTaster_converted_rankscore: 29.75% missing\n",
      "  - i_dbNSFP_MutationTaster_pred: 29.75% missing\n",
      "  - i_dbNSFP_MutationTaster_score: 29.75% missing\n",
      "  - i_dbNSFP_Polyphen2_HDIV_pred: 29.75% missing\n",
      "  - i_dbNSFP_Polyphen2_HDIV_rankscore: 29.75% missing\n",
      "  - i_dbNSFP_Polyphen2_HDIV_score: 29.75% missing\n",
      "  - i_dbNSFP_Polyphen2_HVAR_pred: 29.75% missing\n",
      "  - i_dbNSFP_Polyphen2_HVAR_rankscore: 29.75% missing\n",
      "  - i_dbNSFP_Polyphen2_HVAR_score: 29.75% missing\n",
      "  - i_dbNSFP_RadialSVM_pred: 29.75% missing\n",
      "  - i_dbNSFP_RadialSVM_rankscore: 29.75% missing\n",
      "  - i_dbNSFP_RadialSVM_score: 29.75% missing\n",
      "  - i_dbNSFP_Reliability_index: 29.75% missing\n",
      "  - i_dbNSFP_SIFT_converted_rankscore: 29.75% missing\n",
      "  - i_dbNSFP_SIFT_pred: 29.75% missing\n",
      "  - i_dbNSFP_SIFT_score: 29.75% missing\n",
      "  - i_dbNSFP_SLR_test_statistic: 29.75% missing\n",
      "  - i_dbNSFP_SiPhy_29way_logOdds: 29.75% missing\n",
      "  - i_dbNSFP_SiPhy_29way_logOdds_rankscore: 29.75% missing\n",
      "  - i_dbNSFP_SiPhy_29way_pi: 29.75% missing\n",
      "  - i_dbNSFP_UniSNP_ids: 29.75% missing\n",
      "  - i_dbNSFP_Uniprot_aapos: 29.75% missing\n",
      "  - i_dbNSFP_Uniprot_acc: 29.75% missing\n",
      "  - i_dbNSFP_Uniprot_id: 29.75% missing\n",
      "  - i_dbNSFP_aaalt: 29.75% missing\n",
      "  - i_dbNSFP_aapos: 29.75% missing\n",
      "  - i_dbNSFP_aapos_FATHMM: 29.75% missing\n",
      "  - i_dbNSFP_aapos_SIFT: 29.75% missing\n",
      "  - i_dbNSFP_aaref: 29.75% missing\n",
      "  - i_dbNSFP_cds_strand: 29.75% missing\n",
      "  - i_dbNSFP_codonpos: 29.75% missing\n",
      "  - i_dbNSFP_fold-degenerate: 29.75% missing\n",
      "  - i_dbNSFP_genename: 29.75% missing\n",
      "  - i_dbNSFP_hg18_pos(1-coor): 29.75% missing\n",
      "  - i_dbNSFP_phastCons100way_vertebrate: 29.75% missing\n",
      "  - i_dbNSFP_phastCons100way_vertebrate_rankscore: 29.75% missing\n",
      "  - i_dbNSFP_phastCons46way_placental: 29.75% missing\n",
      "  - i_dbNSFP_phastCons46way_placental_rankscore: 29.75% missing\n",
      "  - i_dbNSFP_phastCons46way_primate: 29.75% missing\n",
      "  - i_dbNSFP_phastCons46way_primate_rankscore: 29.75% missing\n",
      "  - i_dbNSFP_phyloP100way_vertebrate: 29.75% missing\n",
      "  - i_dbNSFP_phyloP100way_vertebrate_rankscore: 29.75% missing\n",
      "  - i_dbNSFP_phyloP46way_placental: 29.75% missing\n",
      "  - i_dbNSFP_phyloP46way_placental_rankscore: 29.75% missing\n",
      "  - i_dbNSFP_phyloP46way_primate: 29.75% missing\n",
      "  - i_dbNSFP_phyloP46way_primate_rankscore: 29.75% missing\n",
      "  - i_dbNSFP_refcodon: 29.75% missing\n",
      "  - i_entrez_gene_id: 99.86% missing\n",
      "  - i_gencode_transcript_name: 0.14% missing\n",
      "  - i_gencode_transcript_status: 0.14% missing\n",
      "  - i_gencode_transcript_tags: 0.14% missing\n",
      "  - i_gencode_transcript_type: 0.14% missing\n",
      "  - i_gene_type: 0.14% missing\n",
      "  - i_havana_transcript: 2.60% missing\n",
      "  - i_refseq_mrna_id: 18.57% missing\n",
      "  - i_secondary_variant_classification: 97.16% missing\n",
      "  - isArtifactMode: 3.65% missing\n",
      "  - oxoGCut: 3.65% missing\n",
      "  - pox: 3.65% missing\n",
      "  - qox: 3.65% missing\n",
      "  - validation_alt_allele: 96.35% missing\n",
      "  - validation_method: 96.35% missing\n",
      "  - validation_status: 96.35% missing\n",
      "  - validation_tumor_sample: 96.35% missing\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def drop_fully_missing_columns(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Import dataset and drop columns with 100% missing values\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the CSV file\n",
    "        print(f\"Reading data from {input_file}...\")\n",
    "        df = pd.read_csv(input_file)\n",
    "        \n",
    "        print(f\"Original data shape: {df.shape}\")\n",
    "        print(f\"Original columns: {len(df.columns)}\")\n",
    "        \n",
    "        # Calculate missing values percentage for each column\n",
    "        missing_percent = (df.isnull().sum() / len(df)) * 100\n",
    "        fully_missing_cols = missing_percent[missing_percent == 100].index.tolist()\n",
    "        \n",
    "        print(f\"\\nColumns with 100% missing values: {len(fully_missing_cols)}\")\n",
    "        if fully_missing_cols:\n",
    "            print(\"Columns to be dropped:\")\n",
    "            for col in fully_missing_cols:\n",
    "                print(f\"  - {col}\")\n",
    "        \n",
    "        # Drop columns with 100% missing values\n",
    "        df_cleaned = df.drop(columns=fully_missing_cols)\n",
    "        \n",
    "        print(f\"\\nCleaned data shape: {df_cleaned.shape}\")\n",
    "        print(f\"Remaining columns: {len(df_cleaned.columns)}\")\n",
    "        \n",
    "        # Save the cleaned dataset\n",
    "        df_cleaned.to_csv(output_file, index=False)\n",
    "        print(f\"\\nCleaned dataset saved to: {output_file}\")\n",
    "        \n",
    "        # Display summary of missing values in remaining columns\n",
    "        remaining_missing = (df_cleaned.isnull().sum() / len(df_cleaned)) * 100\n",
    "        remaining_missing = remaining_missing[remaining_missing > 0]\n",
    "        \n",
    "        if len(remaining_missing) > 0:\n",
    "            print(f\"\\nRemaining columns with some missing values: {len(remaining_missing)}\")\n",
    "            for col, percent in remaining_missing.items():\n",
    "                print(f\"  - {col}: {percent:.2f}% missing\")\n",
    "        else:\n",
    "            print(\"\\nNo missing values in remaining columns!\")\n",
    "        \n",
    "        return df_cleaned\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "input_file = \"csv/mutations.csv\"  \n",
    "output_file = \"csv/mutations.csv\"\n",
    "cleaned_df = drop_fully_missing_columns(input_file, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d762e475",
   "metadata": {},
   "source": [
    "## pathology_detail.csv column cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00a64155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METHOD 1: Drop only completely null columns\n",
      "============================================================\n",
      "Loading data from csv/pathology_detail.csv...\n",
      "Original data shape: (175, 86)\n",
      "Original columns: 86\n",
      "Column to drop: pathology_details.additional_pathology_findings - completely filled with '--\n",
      "Column to drop: pathology_details.anaplasia_present - completely filled with '--\n",
      "Column to drop: pathology_details.anaplasia_present_type - completely filled with '--\n",
      "Column to drop: pathology_details.bone_marrow_malignant_cells - completely filled with '--\n",
      "Column to drop: pathology_details.breslow_thickness - completely filled with '--\n",
      "Column to drop: pathology_details.circumferential_resection_margin - completely filled with '--\n",
      "Column to drop: pathology_details.columnar_mucosa_present - completely filled with '--\n",
      "Column to drop: pathology_details.days_to_pathology_detail - completely filled with '--\n",
      "Column to drop: pathology_details.dysplasia_degree - completely filled with '--\n",
      "Column to drop: pathology_details.dysplasia_type - completely filled with '--\n",
      "Column to drop: pathology_details.epithelioid_cell_percent - completely filled with '--\n",
      "Column to drop: pathology_details.epithelioid_cell_percent_range - completely filled with '--\n",
      "Column to drop: pathology_details.extracapsular_extension - completely filled with '--\n",
      "Column to drop: pathology_details.extracapsular_extension_present - completely filled with '--\n",
      "Column to drop: pathology_details.extraocular_nodule_size - completely filled with '--\n",
      "Column to drop: pathology_details.extrascleral_extension - completely filled with '--\n",
      "Column to drop: pathology_details.extrascleral_extension_present - completely filled with '--\n",
      "Column to drop: pathology_details.extrathyroid_extension - completely filled with '--\n",
      "Column to drop: pathology_details.greatest_tumor_dimension - completely filled with '--\n",
      "Column to drop: pathology_details.gross_tumor_weight - completely filled with '--\n",
      "Column to drop: pathology_details.histologic_progression_type - completely filled with '--\n",
      "Column to drop: pathology_details.intratubular_germ_cell_neoplasia_present - completely filled with '--\n",
      "Column to drop: pathology_details.largest_extrapelvic_peritoneal_focus - completely filled with '--\n",
      "Column to drop: pathology_details.lymph_node_involved_site - completely filled with '--\n",
      "Column to drop: pathology_details.lymph_node_involvement - completely filled with '--\n",
      "Column to drop: pathology_details.lymph_nodes_removed - completely filled with '--\n",
      "Column to drop: pathology_details.measurement_type - completely filled with '--\n",
      "Column to drop: pathology_details.measurement_unit - completely filled with '--\n",
      "Column to drop: pathology_details.metaplasia_present - completely filled with '--\n",
      "Column to drop: pathology_details.micrometastasis_present - completely filled with '--\n",
      "Column to drop: pathology_details.morphologic_architectural_pattern - completely filled with '--\n",
      "Column to drop: pathology_details.necrosis_percent - completely filled with '--\n",
      "Column to drop: pathology_details.necrosis_present - completely filled with '--\n",
      "Column to drop: pathology_details.non_nodal_regional_disease - completely filled with '--\n",
      "Column to drop: pathology_details.non_nodal_tumor_deposits - completely filled with '--\n",
      "Column to drop: pathology_details.number_proliferating_cells - completely filled with '--\n",
      "Column to drop: pathology_details.percent_tumor_invasion - completely filled with '--\n",
      "Column to drop: pathology_details.percent_tumor_nuclei - completely filled with '--\n",
      "Column to drop: pathology_details.peripancreatic_lymph_nodes_positive - completely filled with '--\n",
      "Column to drop: pathology_details.peripancreatic_lymph_nodes_tested - completely filled with '--\n",
      "Column to drop: pathology_details.prcc_type - completely filled with '--\n",
      "Column to drop: pathology_details.prostatic_chips_positive_count - completely filled with '--\n",
      "Column to drop: pathology_details.prostatic_chips_total_count - completely filled with '--\n",
      "Column to drop: pathology_details.prostatic_involvement_percent - completely filled with '--\n",
      "Column to drop: pathology_details.residual_tumor - completely filled with '--\n",
      "Column to drop: pathology_details.residual_tumor_measurement - completely filled with '--\n",
      "Column to drop: pathology_details.rhabdoid_percent - completely filled with '--\n",
      "Column to drop: pathology_details.rhabdoid_present - completely filled with '--\n",
      "Column to drop: pathology_details.sarcomatoid_percent - completely filled with '--\n",
      "Column to drop: pathology_details.sarcomatoid_present - completely filled with '--\n",
      "Column to drop: pathology_details.size_extraocular_nodule - completely filled with '--\n",
      "Column to drop: pathology_details.spindle_cell_percent - completely filled with '--\n",
      "Column to drop: pathology_details.spindle_cell_percent_range - completely filled with '--\n",
      "Column to drop: pathology_details.timepoint_category - completely filled with '--\n",
      "Column to drop: pathology_details.transglottic_extension - completely filled with '--\n",
      "Column to drop: pathology_details.tumor_basal_diameter - completely filled with '--\n",
      "Column to drop: pathology_details.tumor_burden - completely filled with '--\n",
      "Column to drop: pathology_details.tumor_depth_descriptor - completely filled with '--\n",
      "Column to drop: pathology_details.tumor_depth_measurement - completely filled with '--\n",
      "Column to drop: pathology_details.tumor_infiltrating_lymphocytes - completely filled with '--\n",
      "Column to drop: pathology_details.tumor_infiltrating_macrophages - completely filled with '--\n",
      "Column to drop: pathology_details.tumor_largest_dimension_diameter - completely filled with '--\n",
      "Column to drop: pathology_details.tumor_length_measurement - completely filled with '--\n",
      "Column to drop: pathology_details.tumor_level_prostate - completely filled with '--\n",
      "Column to drop: pathology_details.tumor_shape - completely filled with '--\n",
      "Column to drop: pathology_details.tumor_thickness - completely filled with '--\n",
      "Column to drop: pathology_details.tumor_width_measurement - completely filled with '--\n",
      "Column to drop: pathology_details.vascular_invasion_type - completely filled with '--\n",
      "Column to drop: pathology_details.zone_of_origin_prostate - completely filled with '--\n",
      "\n",
      "Dropped 69 columns that were completely null ('--)\n",
      "Cleaned data shape: (175, 17)\n",
      "Remaining columns: 17\n",
      "\n",
      "==================================================\n",
      "NULL VALUE ANALYSIS\n",
      "==================================================\n",
      "\n",
      "Columns with highest percentage of '-- values:\n",
      "------------------------------------------------------------\n",
      "Column                                             Null Count   Null %    \n",
      "------------------------------------------------------------\n",
      "pathology_details.extranodal_extension             122          69.7      \n",
      "pathology_details.lymphatic_invasion_present       119          68.0      \n",
      "pathology_details.vascular_invasion_present        119          68.0      \n",
      "pathology_details.perineural_invasion_present      114          65.1      \n",
      "pathology_details.lymph_nodes_positive             113          64.6      \n",
      "pathology_details.lymph_nodes_tested               108          61.7      \n",
      "pathology_details.margin_status                    101          57.7      \n",
      "pathology_details.consistent_pathology_review      93           53.1      \n",
      "pathology_details.lymph_node_dissection_method     84           48.0      \n",
      "pathology_details.lymph_node_dissection_site       82           46.9      \n",
      "project.project_id                                 0            0.0       \n",
      "cases.case_id                                      0            0.0       \n",
      "cases.submitter_id                                 0            0.0       \n",
      "diagnoses.diagnosis_id                             0            0.0       \n",
      "diagnoses.submitter_id                             0            0.0       \n",
      "pathology_details.pathology_detail_id              0            0.0       \n",
      "pathology_details.submitter_id                     0            0.0       \n",
      "\n",
      "==================================================\n",
      "REPLACING REMAINING '-- WITH NaN\n",
      "==================================================\n",
      "Replaced 1055 '-- values with NaN\n",
      "\n",
      "Cleaned data saved to: pathology_detail_cleaned.csv\n",
      "\n",
      "==================================================\n",
      "CLEANING SUMMARY REPORT\n",
      "==================================================\n",
      "Original shape: (175, 86)\n",
      "Final shape: (175, 17)\n",
      "Columns dropped: 69\n",
      "Total null values after cleaning: 1055\n",
      "Data completeness: 64.5%\n",
      "\n",
      "============================================================\n",
      "METHOD 2: Aggressive cleaning (drop high null columns)\n",
      "============================================================\n",
      "Original shape: (175, 86)\n",
      "\n",
      "Dropping columns with >95% null values:\n",
      "  - pathology_details.additional_pathology_findings (100.0% null)\n",
      "  - pathology_details.anaplasia_present (100.0% null)\n",
      "  - pathology_details.anaplasia_present_type (100.0% null)\n",
      "  - pathology_details.bone_marrow_malignant_cells (100.0% null)\n",
      "  - pathology_details.breslow_thickness (100.0% null)\n",
      "  - pathology_details.circumferential_resection_margin (100.0% null)\n",
      "  - pathology_details.columnar_mucosa_present (100.0% null)\n",
      "  - pathology_details.days_to_pathology_detail (100.0% null)\n",
      "  - pathology_details.dysplasia_degree (100.0% null)\n",
      "  - pathology_details.dysplasia_type (100.0% null)\n",
      "  - pathology_details.epithelioid_cell_percent (100.0% null)\n",
      "  - pathology_details.epithelioid_cell_percent_range (100.0% null)\n",
      "  - pathology_details.extracapsular_extension (100.0% null)\n",
      "  - pathology_details.extracapsular_extension_present (100.0% null)\n",
      "  - pathology_details.extraocular_nodule_size (100.0% null)\n",
      "  - pathology_details.extrascleral_extension (100.0% null)\n",
      "  - pathology_details.extrascleral_extension_present (100.0% null)\n",
      "  - pathology_details.extrathyroid_extension (100.0% null)\n",
      "  - pathology_details.greatest_tumor_dimension (100.0% null)\n",
      "  - pathology_details.gross_tumor_weight (100.0% null)\n",
      "  - pathology_details.histologic_progression_type (100.0% null)\n",
      "  - pathology_details.intratubular_germ_cell_neoplasia_present (100.0% null)\n",
      "  - pathology_details.largest_extrapelvic_peritoneal_focus (100.0% null)\n",
      "  - pathology_details.lymph_node_involved_site (100.0% null)\n",
      "  - pathology_details.lymph_node_involvement (100.0% null)\n",
      "  - pathology_details.lymph_nodes_removed (100.0% null)\n",
      "  - pathology_details.measurement_type (100.0% null)\n",
      "  - pathology_details.measurement_unit (100.0% null)\n",
      "  - pathology_details.metaplasia_present (100.0% null)\n",
      "  - pathology_details.micrometastasis_present (100.0% null)\n",
      "  - pathology_details.morphologic_architectural_pattern (100.0% null)\n",
      "  - pathology_details.necrosis_percent (100.0% null)\n",
      "  - pathology_details.necrosis_present (100.0% null)\n",
      "  - pathology_details.non_nodal_regional_disease (100.0% null)\n",
      "  - pathology_details.non_nodal_tumor_deposits (100.0% null)\n",
      "  - pathology_details.number_proliferating_cells (100.0% null)\n",
      "  - pathology_details.percent_tumor_invasion (100.0% null)\n",
      "  - pathology_details.percent_tumor_nuclei (100.0% null)\n",
      "  - pathology_details.peripancreatic_lymph_nodes_positive (100.0% null)\n",
      "  - pathology_details.peripancreatic_lymph_nodes_tested (100.0% null)\n",
      "  - pathology_details.prcc_type (100.0% null)\n",
      "  - pathology_details.prostatic_chips_positive_count (100.0% null)\n",
      "  - pathology_details.prostatic_chips_total_count (100.0% null)\n",
      "  - pathology_details.prostatic_involvement_percent (100.0% null)\n",
      "  - pathology_details.residual_tumor (100.0% null)\n",
      "  - pathology_details.residual_tumor_measurement (100.0% null)\n",
      "  - pathology_details.rhabdoid_percent (100.0% null)\n",
      "  - pathology_details.rhabdoid_present (100.0% null)\n",
      "  - pathology_details.sarcomatoid_percent (100.0% null)\n",
      "  - pathology_details.sarcomatoid_present (100.0% null)\n",
      "  - pathology_details.size_extraocular_nodule (100.0% null)\n",
      "  - pathology_details.spindle_cell_percent (100.0% null)\n",
      "  - pathology_details.spindle_cell_percent_range (100.0% null)\n",
      "  - pathology_details.timepoint_category (100.0% null)\n",
      "  - pathology_details.transglottic_extension (100.0% null)\n",
      "  - pathology_details.tumor_basal_diameter (100.0% null)\n",
      "  - pathology_details.tumor_burden (100.0% null)\n",
      "  - pathology_details.tumor_depth_descriptor (100.0% null)\n",
      "  - pathology_details.tumor_depth_measurement (100.0% null)\n",
      "  - pathology_details.tumor_infiltrating_lymphocytes (100.0% null)\n",
      "  - pathology_details.tumor_infiltrating_macrophages (100.0% null)\n",
      "  - pathology_details.tumor_largest_dimension_diameter (100.0% null)\n",
      "  - pathology_details.tumor_length_measurement (100.0% null)\n",
      "  - pathology_details.tumor_level_prostate (100.0% null)\n",
      "  - pathology_details.tumor_shape (100.0% null)\n",
      "  - pathology_details.tumor_thickness (100.0% null)\n",
      "  - pathology_details.tumor_width_measurement (100.0% null)\n",
      "  - pathology_details.vascular_invasion_type (100.0% null)\n",
      "  - pathology_details.zone_of_origin_prostate (100.0% null)\n",
      "\n",
      "After aggressive cleaning:\n",
      "  Shape: (175, 17)\n",
      "  Columns dropped: 69\n",
      "  Remaining columns: 17\n",
      "Saved to: pathology_detail_aggressive_cleaned.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ibrahim\\AppData\\Local\\Temp\\ipykernel_10540\\678921372.py:127: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(\"'--\", np.nan)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def clean_pathology_data(file_path):\n",
    "    \"\"\"\n",
    "    Load pathology data and drop columns that are completely filled with '-- values\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read the CSV file\n",
    "    print(f\"Loading data from {file_path}...\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    print(f\"Original data shape: {df.shape}\")\n",
    "    print(f\"Original columns: {len(df.columns)}\")\n",
    "    \n",
    "    # Identify columns that are completely filled with '--\n",
    "    columns_to_drop = []\n",
    "    \n",
    "    for column in df.columns:\n",
    "        # Check if all values in the column are '--\n",
    "        if (df[column] == \"'--\").all():\n",
    "            columns_to_drop.append(column)\n",
    "            print(f\"Column to drop: {column} - completely filled with '--\")\n",
    "    \n",
    "    # Drop the identified columns\n",
    "    if columns_to_drop:\n",
    "        df_cleaned = df.drop(columns=columns_to_drop)\n",
    "        print(f\"\\nDropped {len(columns_to_drop)} columns that were completely null ('--)\")\n",
    "    else:\n",
    "        df_cleaned = df\n",
    "        print(\"No completely null columns found to drop\")\n",
    "    \n",
    "    print(f\"Cleaned data shape: {df_cleaned.shape}\")\n",
    "    print(f\"Remaining columns: {len(df_cleaned.columns)}\")\n",
    "    \n",
    "    return df_cleaned, columns_to_drop\n",
    "\n",
    "def analyze_null_patterns(df):\n",
    "    \"\"\"\n",
    "    Analyze the pattern of null values in the dataset\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"NULL VALUE ANALYSIS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Count '-- values in each column\n",
    "    null_counts = {}\n",
    "    total_rows = len(df)\n",
    "    \n",
    "    for column in df.columns:\n",
    "        null_count = (df[column] == \"'--\").sum()\n",
    "        null_percentage = (null_count / total_rows) * 100\n",
    "        null_counts[column] = {\n",
    "            'null_count': null_count,\n",
    "            'null_percentage': null_percentage\n",
    "        }\n",
    "    \n",
    "    # Sort by null percentage\n",
    "    sorted_null_counts = dict(sorted(null_counts.items(), \n",
    "                                   key=lambda x: x[1]['null_percentage'], \n",
    "                                   reverse=True))\n",
    "    \n",
    "    print(\"\\nColumns with highest percentage of '-- values:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'Column':<50} {'Null Count':<12} {'Null %':<10}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for col, stats in list(sorted_null_counts.items())[:20]:  # Top 20\n",
    "        print(f\"{col:<50} {stats['null_count']:<12} {stats['null_percentage']:<10.1f}\")\n",
    "    \n",
    "    return sorted_null_counts\n",
    "\n",
    "def create_cleaned_dataset(file_path, output_path=None):\n",
    "    \"\"\"\n",
    "    Complete pipeline to clean the pathology data\n",
    "    \"\"\"\n",
    "    # Step 1: Clean the data\n",
    "    df_cleaned, dropped_columns = clean_pathology_data(file_path)\n",
    "    \n",
    "    # Step 2: Analyze null patterns\n",
    "    null_analysis = analyze_null_patterns(df_cleaned)\n",
    "    \n",
    "    # Step 3: Additional cleaning - replace remaining '-- with actual NaN\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"REPLACING REMAINING '-- WITH NaN\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Replace all remaining '-- with NaN for better pandas handling\n",
    "    df_final = df_cleaned.replace(\"'--\", np.nan)\n",
    "    \n",
    "    # Count how many values were replaced\n",
    "    total_replaced = df_final.isna().sum().sum() - df_cleaned.isna().sum().sum()\n",
    "    print(f\"Replaced {total_replaced} '-- values with NaN\")\n",
    "    \n",
    "    # Step 4: Save the cleaned data\n",
    "    if output_path:\n",
    "        df_final.to_csv(output_path, index=False)\n",
    "        print(f\"\\nCleaned data saved to: {output_path}\")\n",
    "    \n",
    "    # Step 5: Generate summary report\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"CLEANING SUMMARY REPORT\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Original shape: {pd.read_csv(file_path).shape}\")\n",
    "    print(f\"Final shape: {df_final.shape}\")\n",
    "    print(f\"Columns dropped: {len(dropped_columns)}\")\n",
    "    print(f\"Total null values after cleaning: {df_final.isna().sum().sum()}\")\n",
    "    print(f\"Data completeness: {(1 - df_final.isna().sum().sum() / (df_final.shape[0] * df_final.shape[1])) * 100:.1f}%\")\n",
    "    \n",
    "    # Show remaining columns with high null rates (optional further cleaning)\n",
    "    high_null_cols = {k: v for k, v in null_analysis.items() if v['null_percentage'] > 90}\n",
    "    if high_null_cols:\n",
    "        print(f\"\\nColumns with >90% null values (consider dropping): {len(high_null_cols)}\")\n",
    "        for col in list(high_null_cols.keys())[:10]:  # Show first 10\n",
    "            print(f\"  - {col}\")\n",
    "    \n",
    "    return df_final, dropped_columns\n",
    "\n",
    "# Alternative function for more aggressive cleaning\n",
    "def aggressive_clean(file_path, null_threshold=95, output_path=None):\n",
    "    \"\"\"\n",
    "    More aggressive cleaning that drops columns with high percentage of null values\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Replace '-- with NaN first\n",
    "    df = df.replace(\"'--\", np.nan)\n",
    "    \n",
    "    print(f\"Original shape: {df.shape}\")\n",
    "    \n",
    "    # Calculate null percentage for each column\n",
    "    null_percentages = (df.isnull().sum() / len(df)) * 100\n",
    "    \n",
    "    # Identify columns to drop based on threshold\n",
    "    columns_to_drop = null_percentages[null_percentages > null_threshold].index.tolist()\n",
    "    \n",
    "    print(f\"\\nDropping columns with >{null_threshold}% null values:\")\n",
    "    for col in columns_to_drop:\n",
    "        print(f\"  - {col} ({null_percentages[col]:.1f}% null)\")\n",
    "    \n",
    "    # Drop columns\n",
    "    df_cleaned = df.drop(columns=columns_to_drop)\n",
    "    \n",
    "    print(f\"\\nAfter aggressive cleaning:\")\n",
    "    print(f\"  Shape: {df_cleaned.shape}\")\n",
    "    print(f\"  Columns dropped: {len(columns_to_drop)}\")\n",
    "    print(f\"  Remaining columns: {len(df_cleaned.columns)}\")\n",
    "    \n",
    "    if output_path:\n",
    "        df_cleaned.to_csv(output_path, index=False)\n",
    "        print(f\"Saved to: {output_path}\")\n",
    "    \n",
    "    return df_cleaned, columns_to_drop\n",
    "\n",
    "# Usage examples:\n",
    "\n",
    "if True:\n",
    "    file_path = \"csv/pathology_detail.csv\"\n",
    "    \n",
    "    print(\"METHOD 1: Drop only completely null columns\")\n",
    "    print(\"=\"*60)\n",
    "    df_cleaned1, dropped1 = create_cleaned_dataset(\n",
    "        file_path, \n",
    "        output_path=\"pathology_detail_cleaned.csv\"\n",
    "    )\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"METHOD 2: Aggressive cleaning (drop high null columns)\")\n",
    "    print(\"=\"*60)\n",
    "    df_cleaned2, dropped2 = aggressive_clean(\n",
    "        file_path,\n",
    "        null_threshold=95,  # Drop columns with >95% null values\n",
    "        output_path=\"pathology_detail_aggressive_cleaned.csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6ffcdf",
   "metadata": {},
   "source": [
    "## For Exposure file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36aaabe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METHOD 1: Drop only completely null columns\n",
      "============================================================\n",
      "Loading data from csv/exposure.csv...\n",
      "Original data shape: (114, 40)\n",
      "Original columns: 40\n",
      "Column to drop: exposures.age_at_last_exposure - completely filled with '--\n",
      "Column to drop: exposures.age_at_onset - completely filled with '--\n",
      "Column to drop: exposures.alcohol_frequency - completely filled with '--\n",
      "Column to drop: exposures.alcohol_intensity - completely filled with '--\n",
      "Column to drop: exposures.alcohol_type - completely filled with '--\n",
      "Column to drop: exposures.asbestos_exposure - completely filled with '--\n",
      "Column to drop: exposures.asbestos_exposure_type - completely filled with '--\n",
      "Column to drop: exposures.chemical_exposure_type - completely filled with '--\n",
      "Column to drop: exposures.cigarettes_per_day - completely filled with '--\n",
      "Column to drop: exposures.coal_dust_exposure - completely filled with '--\n",
      "Column to drop: exposures.environmental_tobacco_smoke_exposure - completely filled with '--\n",
      "Column to drop: exposures.exposure_duration - completely filled with '--\n",
      "Column to drop: exposures.exposure_duration_hrs_per_day - completely filled with '--\n",
      "Column to drop: exposures.exposure_duration_years - completely filled with '--\n",
      "Column to drop: exposures.exposure_id - completely filled with '--\n",
      "Column to drop: exposures.exposure_source - completely filled with '--\n",
      "Column to drop: exposures.occupation_duration_years - completely filled with '--\n",
      "Column to drop: exposures.occupation_type - completely filled with '--\n",
      "Column to drop: exposures.parent_with_radiation_exposure - completely filled with '--\n",
      "Column to drop: exposures.radon_exposure - completely filled with '--\n",
      "Column to drop: exposures.respirable_crystalline_silica_exposure - completely filled with '--\n",
      "Column to drop: exposures.secondhand_smoke_as_child - completely filled with '--\n",
      "Column to drop: exposures.smoking_frequency - completely filled with '--\n",
      "Column to drop: exposures.submitter_id - completely filled with '--\n",
      "Column to drop: exposures.time_between_waking_and_first_smoke - completely filled with '--\n",
      "Column to drop: exposures.type_of_smoke_exposure - completely filled with '--\n",
      "Column to drop: exposures.type_of_tobacco_used - completely filled with '--\n",
      "Column to drop: exposures.use_per_day - completely filled with '--\n",
      "Column to drop: exposures.years_smoked - completely filled with '--\n",
      "\n",
      "Dropped 29 columns that were completely null ('--)\n",
      "Cleaned data shape: (114, 11)\n",
      "Remaining columns: 11\n",
      "\n",
      "==================================================\n",
      "NULL VALUE ANALYSIS\n",
      "==================================================\n",
      "\n",
      "Columns with highest percentage of '-- values:\n",
      "------------------------------------------------------------\n",
      "Column                                             Null Count   Null %    \n",
      "------------------------------------------------------------\n",
      "project.project_id                                 0            0.0       \n",
      "cases.case_id                                      0            0.0       \n",
      "cases.submitter_id                                 0            0.0       \n",
      "exposures.alcohol_days_per_week                    0            0.0       \n",
      "exposures.alcohol_drinks_per_day                   0            0.0       \n",
      "exposures.alcohol_history                          0            0.0       \n",
      "exposures.exposure_type                            0            0.0       \n",
      "exposures.pack_years_smoked                        0            0.0       \n",
      "exposures.tobacco_smoking_onset_year               0            0.0       \n",
      "exposures.tobacco_smoking_quit_year                0            0.0       \n",
      "exposures.tobacco_smoking_status                   0            0.0       \n",
      "\n",
      "==================================================\n",
      "REPLACING REMAINING '-- WITH NaN\n",
      "==================================================\n",
      "Replaced 0 '-- values with NaN\n",
      "\n",
      "Cleaned data saved to: exposure.csv\n",
      "\n",
      "==================================================\n",
      "CLEANING SUMMARY REPORT\n",
      "==================================================\n",
      "Original shape: (114, 40)\n",
      "Final shape: (114, 11)\n",
      "Columns dropped: 29\n",
      "Total null values after cleaning: 0\n",
      "Data completeness: 100.0%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def clean_pathology_data(file_path):\n",
    "    \"\"\"\n",
    "    Load pathology data and drop columns that are completely filled with '-- values\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read the CSV file\n",
    "    print(f\"Loading data from {file_path}...\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    print(f\"Original data shape: {df.shape}\")\n",
    "    print(f\"Original columns: {len(df.columns)}\")\n",
    "    \n",
    "    # Identify columns that are completely filled with '--\n",
    "    columns_to_drop = []\n",
    "    \n",
    "    for column in df.columns:\n",
    "        # Check if all values in the column are '--\n",
    "        if (df[column] == \"-\").all():\n",
    "            columns_to_drop.append(column)\n",
    "            print(f\"Column to drop: {column} - completely filled with '--\")\n",
    "    \n",
    "    # Drop the identified columns\n",
    "    if columns_to_drop:\n",
    "        df_cleaned = df.drop(columns=columns_to_drop)\n",
    "        print(f\"\\nDropped {len(columns_to_drop)} columns that were completely null ('--)\")\n",
    "    else:\n",
    "        df_cleaned = df\n",
    "        print(\"No completely null columns found to drop\")\n",
    "    \n",
    "    print(f\"Cleaned data shape: {df_cleaned.shape}\")\n",
    "    print(f\"Remaining columns: {len(df_cleaned.columns)}\")\n",
    "    \n",
    "    return df_cleaned, columns_to_drop\n",
    "\n",
    "def analyze_null_patterns(df):\n",
    "    \"\"\"\n",
    "    Analyze the pattern of null values in the dataset\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"NULL VALUE ANALYSIS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Count '-- values in each column\n",
    "    null_counts = {}\n",
    "    total_rows = len(df)\n",
    "    \n",
    "    for column in df.columns:\n",
    "        null_count = (df[column] == \"'--\").sum()\n",
    "        null_percentage = (null_count / total_rows) * 100\n",
    "        null_counts[column] = {\n",
    "            'null_count': null_count,\n",
    "            'null_percentage': null_percentage\n",
    "        }\n",
    "    \n",
    "    # Sort by null percentage\n",
    "    sorted_null_counts = dict(sorted(null_counts.items(), \n",
    "                                   key=lambda x: x[1]['null_percentage'], \n",
    "                                   reverse=True))\n",
    "    \n",
    "    print(\"\\nColumns with highest percentage of '-- values:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'Column':<50} {'Null Count':<12} {'Null %':<10}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for col, stats in list(sorted_null_counts.items())[:20]:  # Top 20\n",
    "        print(f\"{col:<50} {stats['null_count']:<12} {stats['null_percentage']:<10.1f}\")\n",
    "    \n",
    "    return sorted_null_counts\n",
    "\n",
    "def create_cleaned_dataset(file_path, output_path=None):\n",
    "    \"\"\"\n",
    "    Complete pipeline to clean the pathology data\n",
    "    \"\"\"\n",
    "    # Step 1: Clean the data\n",
    "    df_cleaned, dropped_columns = clean_pathology_data(file_path)\n",
    "    \n",
    "    # Step 2: Analyze null patterns\n",
    "    null_analysis = analyze_null_patterns(df_cleaned)\n",
    "    \n",
    "    # Step 3: Additional cleaning - replace remaining '-- with actual NaN\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"REPLACING REMAINING '-- WITH NaN\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Replace all remaining '-- with NaN for better pandas handling\n",
    "    df_final = df_cleaned.replace(\"'--\", np.nan)\n",
    "    \n",
    "    # Count how many values were replaced\n",
    "    total_replaced = df_final.isna().sum().sum() - df_cleaned.isna().sum().sum()\n",
    "    print(f\"Replaced {total_replaced} '-- values with NaN\")\n",
    "    \n",
    "    # Step 4: Save the cleaned data\n",
    "    if output_path:\n",
    "        df_final.to_csv(output_path, index=False)\n",
    "        print(f\"\\nCleaned data saved to: {output_path}\")\n",
    "    \n",
    "    # Step 5: Generate summary report\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"CLEANING SUMMARY REPORT\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Original shape: {pd.read_csv(file_path).shape}\")\n",
    "    print(f\"Final shape: {df_final.shape}\")\n",
    "    print(f\"Columns dropped: {len(dropped_columns)}\")\n",
    "    print(f\"Total null values after cleaning: {df_final.isna().sum().sum()}\")\n",
    "    print(f\"Data completeness: {(1 - df_final.isna().sum().sum() / (df_final.shape[0] * df_final.shape[1])) * 100:.1f}%\")\n",
    "    \n",
    "    # Show remaining columns with high null rates (optional further cleaning)\n",
    "    high_null_cols = {k: v for k, v in null_analysis.items() if v['null_percentage'] > 90}\n",
    "    if high_null_cols:\n",
    "        print(f\"\\nColumns with >90% null values (consider dropping): {len(high_null_cols)}\")\n",
    "        for col in list(high_null_cols.keys())[:10]:  # Show first 10\n",
    "            print(f\"  - {col}\")\n",
    "    \n",
    "    return df_final, dropped_columns\n",
    "\n",
    "# Alternative function for more aggressive cleaning\n",
    "def aggressive_clean(file_path, null_threshold=95, output_path=None):\n",
    "    \"\"\"\n",
    "    More aggressive cleaning that drops columns with high percentage of null values\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Replace '-- with NaN first\n",
    "    df = df.replace(\"-\", np.nan)\n",
    "    \n",
    "    print(f\"Original shape: {df.shape}\")\n",
    "    \n",
    "    # Calculate null percentage for each column\n",
    "    null_percentages = (df.isnull().sum() / len(df)) * 100\n",
    "    \n",
    "    # Identify columns to drop based on threshold\n",
    "    columns_to_drop = null_percentages[null_percentages > null_threshold].index.tolist()\n",
    "    \n",
    "    print(f\"\\nDropping columns with >{null_threshold}% null values:\")\n",
    "    for col in columns_to_drop:\n",
    "        print(f\"  - {col} ({null_percentages[col]:.1f}% null)\")\n",
    "    \n",
    "    # Drop columns\n",
    "    df_cleaned = df.drop(columns=columns_to_drop)\n",
    "    \n",
    "    print(f\"\\nAfter aggressive cleaning:\")\n",
    "    print(f\"  Shape: {df_cleaned.shape}\")\n",
    "    print(f\"  Columns dropped: {len(columns_to_drop)}\")\n",
    "    print(f\"  Remaining columns: {len(df_cleaned.columns)}\")\n",
    "    \n",
    "    if output_path:\n",
    "        df_cleaned.to_csv(output_path, index=False)\n",
    "        print(f\"Saved to: {output_path}\")\n",
    "    \n",
    "    return df_cleaned, columns_to_drop\n",
    "\n",
    "# Usage examples:\n",
    "\n",
    "if True:\n",
    "    file_path = \"csv/exposure.csv\"\n",
    "    \n",
    "    print(\"METHOD 1: Drop only completely null columns\")\n",
    "    print(\"=\"*60)\n",
    "    df_cleaned1, dropped1 = create_cleaned_dataset(\n",
    "        file_path, \n",
    "        output_path=\"exposure.csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54aa084",
   "metadata": {},
   "source": [
    "## For merging 3 datasets and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f81e8de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset created successfully!\n",
      "Shape: (1779, 102)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "clinical = pd.read_csv(\"csv/clinical.csv\", sep=\",\")\n",
    "exposure = pd.read_csv(\"csv/exposure.csv\", sep=\",\")\n",
    "follow_up = pd.read_csv(\"csv/follow_up.csv\", sep=\",\")\n",
    "key = \"cases.case_id\"\n",
    "if key not in clinical.columns:\n",
    "    raise KeyError(f\"{key} not found in clinical.txt\")\n",
    "if key not in exposure.columns:\n",
    "    raise KeyError(f\"{key} not found in exposure.txt\")\n",
    "if key not in follow_up.columns:\n",
    "    raise KeyError(f\"{key} not found in follow_up.txt\")\n",
    "\n",
    "clinical[key] = clinical[key].astype(str)\n",
    "exposure[key] = exposure[key].astype(str)\n",
    "follow_up[key] = follow_up[key].astype(str)\n",
    "\n",
    "# -------------------------\n",
    "# Merge datasets with FULL OUTER JOIN (no data loss)\n",
    "# -------------------------\n",
    "merged = clinical.merge(exposure, on=key, how=\"outer\")\n",
    "merged = merged.merge(follow_up, on=key, how=\"outer\")\n",
    "merged.to_csv(\"merged_clinical_exposure_followup.csv\", index=False)\n",
    "print(\"Merged dataset created successfully!\")\n",
    "print(\"Shape:\", merged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "202adc04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Finished! Output saved as merged_clinical_exposure_followup_CLEAN.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Load your merged dataset\n",
    "# ---------------------------------------------------------\n",
    "df = pd.read_csv(\"merged_clinical_exposure_followup.csv\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. Sort by `cases.case_id` and `cases.submitter_id_x`\n",
    "# ---------------------------------------------------------\n",
    "# Ensure both columns exist\n",
    "if \"cases.case_id\" not in df.columns:\n",
    "    raise KeyError(\"Column 'cases.case_id' not found!\")\n",
    "\n",
    "if \"cases.submitter_id_x\" not in df.columns:\n",
    "    raise KeyError(\"Column 'cases.submitter_id_x' not found!\")\n",
    "\n",
    "# Sort\n",
    "df = df.sort_values(by=[\"cases.case_id\", \"cases.submitter_id_x\"], ascending=[True, True])\n",
    "\n",
    "# Move the two columns to the front next to each other\n",
    "cols = df.columns.tolist()\n",
    "cols.remove(\"cases.case_id\")\n",
    "cols.remove(\"cases.submitter_id_x\")\n",
    "df = df[[\"cases.case_id\", \"cases.submitter_id_x\"] + cols]\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. Concatenate cases.disease_type + cases.index_date\n",
    "# ---------------------------------------------------------\n",
    "if \"cases.disease_type\" in df.columns and \"cases.index_date\" in df.columns:\n",
    "    df[\"cases.disease_index\"] = df[\"cases.disease_type\"].fillna(\"\") + \" | \" + df[\"cases.index_date\"].fillna(\"\")\n",
    "    df[\"cases.disease_index\"] = df[\"cases.disease_index\"].str.strip(\" |\")\n",
    "else:\n",
    "    print(\"Warning: 'cases.disease_type' or 'cases.index_date' not found.\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. Combine demographic.ethnicity + demographic.race\n",
    "# ---------------------------------------------------------\n",
    "eth_col = \"demographic.ethnicity\"\n",
    "race_col = \"demographic.race\"\n",
    "\n",
    "if eth_col in df.columns and race_col in df.columns:\n",
    "    df[\"demographic.ethnicity_race\"] = (\n",
    "        df[eth_col].fillna(\"\") + \" - \" + df[race_col].fillna(\"\")\n",
    "    ).str.strip(\" -\")\n",
    "else:\n",
    "    print(\"Warning: Ethnicity or Race column missing!\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Save cleaned output\n",
    "# ---------------------------------------------------------\n",
    "df.to_csv(\"merged_clinical_exposure_followup_CLEAN.csv\", index=False)\n",
    "\n",
    "print(\" Finished! Output saved as merged_clinical_exposure_followup_CLEAN.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fb0bf0",
   "metadata": {},
   "source": [
    "## Combining the transcriptomics.csv and methylation.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77e19b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common matched samples: 88\n",
      "Common genes: 19223\n",
      "Transcriptomics aligned shape: (19224, 88)\n",
      "Methylation aligned shape: (19223, 88)\n",
      "Final combined shape: (19224, 88)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TCGA-BA-4074-01</th>\n",
       "      <th>TCGA-BA-4077-01</th>\n",
       "      <th>TCGA-BA-5153-01</th>\n",
       "      <th>TCGA-BA-5556-01</th>\n",
       "      <th>TCGA-BA-5557-01</th>\n",
       "      <th>TCGA-BA-6872-01</th>\n",
       "      <th>TCGA-BA-6873-01</th>\n",
       "      <th>TCGA-BA-7269-01</th>\n",
       "      <th>TCGA-BB-4224-01</th>\n",
       "      <th>TCGA-BB-4225-01</th>\n",
       "      <th>...</th>\n",
       "      <th>TCGA-CX-7082-01</th>\n",
       "      <th>TCGA-CX-7086-01</th>\n",
       "      <th>TCGA-D6-6516-01</th>\n",
       "      <th>TCGA-D6-6823-01</th>\n",
       "      <th>TCGA-DQ-5624-01</th>\n",
       "      <th>TCGA-DQ-5625-01</th>\n",
       "      <th>TCGA-DQ-5631-01</th>\n",
       "      <th>TCGA-DQ-7588-01</th>\n",
       "      <th>TCGA-H7-7774-01</th>\n",
       "      <th>TCGA-HD-7831-01</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gene_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1-Dec</th>\n",
       "      <td>248.493765</td>\n",
       "      <td>4.758282</td>\n",
       "      <td>0.365159</td>\n",
       "      <td>6.657963</td>\n",
       "      <td>0.805727</td>\n",
       "      <td>4.849233</td>\n",
       "      <td>5.022764</td>\n",
       "      <td>1.704351</td>\n",
       "      <td>12.839721</td>\n",
       "      <td>0.476125</td>\n",
       "      <td>...</td>\n",
       "      <td>8.573603</td>\n",
       "      <td>10.687611</td>\n",
       "      <td>5.656634</td>\n",
       "      <td>23.265784</td>\n",
       "      <td>2.689164</td>\n",
       "      <td>1.858466</td>\n",
       "      <td>16.826791</td>\n",
       "      <td>59.067935</td>\n",
       "      <td>0.531164</td>\n",
       "      <td>21.919849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-Mar</th>\n",
       "      <td>136.125609</td>\n",
       "      <td>419.006642</td>\n",
       "      <td>75.269811</td>\n",
       "      <td>355.740175</td>\n",
       "      <td>369.288649</td>\n",
       "      <td>26.215438</td>\n",
       "      <td>38.651937</td>\n",
       "      <td>8.460583</td>\n",
       "      <td>217.069578</td>\n",
       "      <td>276.526602</td>\n",
       "      <td>...</td>\n",
       "      <td>255.177937</td>\n",
       "      <td>95.467913</td>\n",
       "      <td>181.188416</td>\n",
       "      <td>64.200249</td>\n",
       "      <td>157.579292</td>\n",
       "      <td>332.350287</td>\n",
       "      <td>292.322759</td>\n",
       "      <td>29.911578</td>\n",
       "      <td>132.367060</td>\n",
       "      <td>82.262493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-Sep</th>\n",
       "      <td>149.718523</td>\n",
       "      <td>498.166243</td>\n",
       "      <td>1101.357375</td>\n",
       "      <td>1373.367825</td>\n",
       "      <td>337.641897</td>\n",
       "      <td>186.749782</td>\n",
       "      <td>221.266162</td>\n",
       "      <td>232.157075</td>\n",
       "      <td>158.134833</td>\n",
       "      <td>1375.880360</td>\n",
       "      <td>...</td>\n",
       "      <td>504.807808</td>\n",
       "      <td>272.066124</td>\n",
       "      <td>531.682620</td>\n",
       "      <td>259.547108</td>\n",
       "      <td>408.340166</td>\n",
       "      <td>928.326002</td>\n",
       "      <td>166.187729</td>\n",
       "      <td>97.244087</td>\n",
       "      <td>391.518146</td>\n",
       "      <td>162.325708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10-Mar</th>\n",
       "      <td>114.215866</td>\n",
       "      <td>6.736469</td>\n",
       "      <td>3.366613</td>\n",
       "      <td>3.924946</td>\n",
       "      <td>1.449906</td>\n",
       "      <td>5.851599</td>\n",
       "      <td>29.419235</td>\n",
       "      <td>5.599466</td>\n",
       "      <td>46.273094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.656245</td>\n",
       "      <td>0.582764</td>\n",
       "      <td>6.706357</td>\n",
       "      <td>3.541566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.834903</td>\n",
       "      <td>8.906240</td>\n",
       "      <td>20.022391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.607995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10-Sep</th>\n",
       "      <td>14402.328014</td>\n",
       "      <td>11241.679840</td>\n",
       "      <td>9136.669608</td>\n",
       "      <td>9255.783136</td>\n",
       "      <td>8942.622941</td>\n",
       "      <td>3998.016649</td>\n",
       "      <td>4074.463859</td>\n",
       "      <td>3740.011866</td>\n",
       "      <td>10427.833554</td>\n",
       "      <td>5448.996823</td>\n",
       "      <td>...</td>\n",
       "      <td>10138.991480</td>\n",
       "      <td>11919.509939</td>\n",
       "      <td>7295.099708</td>\n",
       "      <td>10891.616299</td>\n",
       "      <td>11828.240871</td>\n",
       "      <td>11197.224660</td>\n",
       "      <td>20315.463867</td>\n",
       "      <td>7820.665859</td>\n",
       "      <td>7763.630358</td>\n",
       "      <td>5902.336920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         TCGA-BA-4074-01  TCGA-BA-4077-01  TCGA-BA-5153-01  TCGA-BA-5556-01  \\\n",
       "gene_id                                                                       \n",
       "1-Dec         248.493765         4.758282         0.365159         6.657963   \n",
       "1-Mar         136.125609       419.006642        75.269811       355.740175   \n",
       "1-Sep         149.718523       498.166243      1101.357375      1373.367825   \n",
       "10-Mar        114.215866         6.736469         3.366613         3.924946   \n",
       "10-Sep      14402.328014     11241.679840      9136.669608      9255.783136   \n",
       "\n",
       "         TCGA-BA-5557-01  TCGA-BA-6872-01  TCGA-BA-6873-01  TCGA-BA-7269-01  \\\n",
       "gene_id                                                                       \n",
       "1-Dec           0.805727         4.849233         5.022764         1.704351   \n",
       "1-Mar         369.288649        26.215438        38.651937         8.460583   \n",
       "1-Sep         337.641897       186.749782       221.266162       232.157075   \n",
       "10-Mar          1.449906         5.851599        29.419235         5.599466   \n",
       "10-Sep       8942.622941      3998.016649      4074.463859      3740.011866   \n",
       "\n",
       "         TCGA-BB-4224-01  TCGA-BB-4225-01  ...  TCGA-CX-7082-01  \\\n",
       "gene_id                                    ...                    \n",
       "1-Dec          12.839721         0.476125  ...         8.573603   \n",
       "1-Mar         217.069578       276.526602  ...       255.177937   \n",
       "1-Sep         158.134833      1375.880360  ...       504.807808   \n",
       "10-Mar         46.273094         0.000000  ...         3.656245   \n",
       "10-Sep      10427.833554      5448.996823  ...     10138.991480   \n",
       "\n",
       "         TCGA-CX-7086-01  TCGA-D6-6516-01  TCGA-D6-6823-01  TCGA-DQ-5624-01  \\\n",
       "gene_id                                                                       \n",
       "1-Dec          10.687611         5.656634        23.265784         2.689164   \n",
       "1-Mar          95.467913       181.188416        64.200249       157.579292   \n",
       "1-Sep         272.066124       531.682620       259.547108       408.340166   \n",
       "10-Mar          0.582764         6.706357         3.541566         0.000000   \n",
       "10-Sep      11919.509939      7295.099708     10891.616299     11828.240871   \n",
       "\n",
       "         TCGA-DQ-5625-01  TCGA-DQ-5631-01  TCGA-DQ-7588-01  TCGA-H7-7774-01  \\\n",
       "gene_id                                                                       \n",
       "1-Dec           1.858466        16.826791        59.067935         0.531164   \n",
       "1-Mar         332.350287       292.322759        29.911578       132.367060   \n",
       "1-Sep         928.326002       166.187729        97.244087       391.518146   \n",
       "10-Mar          0.834903         8.906240        20.022391         0.000000   \n",
       "10-Sep      11197.224660     20315.463867      7820.665859      7763.630358   \n",
       "\n",
       "         TCGA-HD-7831-01  \n",
       "gene_id                   \n",
       "1-Dec          21.919849  \n",
       "1-Mar          82.262493  \n",
       "1-Sep         162.325708  \n",
       "10-Mar          4.607995  \n",
       "10-Sep       5902.336920  \n",
       "\n",
       "[5 rows x 88 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 1. Load datasets\n",
    "# ----------------------------------------------\n",
    "df_trans = pd.read_csv(\"csv/transcriptomics.csv\")\n",
    "df_meth  = pd.read_csv(\"csv/methylation.csv\")\n",
    "\n",
    "df_meth = df_meth.rename(columns={'V1': 'gene_id'})\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 2. Normalize TCGA IDs\n",
    "# ----------------------------------------------\n",
    "def normalize_id(col):\n",
    "    if isinstance(col, str) and col.startswith(\"TCGA\"):\n",
    "        parts = col.split(\"-\")\n",
    "        if len(parts) >= 4:\n",
    "            return f\"{parts[0]}-{parts[1]}-{parts[2]}-{parts[3][:2]}\"\n",
    "    return col\n",
    "\n",
    "df_trans.columns = [normalize_id(c) for c in df_trans.columns]\n",
    "df_meth.columns  = [normalize_id(c) for c in df_meth.columns]\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 3. Find common samples\n",
    "# ----------------------------------------------\n",
    "trans_samples = set(df_trans.columns) - {\"gene_id\"}\n",
    "meth_samples  = set(df_meth.columns) - {\"gene_id\"}\n",
    "\n",
    "common_samples = sorted(trans_samples.intersection(meth_samples))\n",
    "print(\"Common matched samples:\", len(common_samples))\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 4. Find common GENES (IMPORTANT FIX)\n",
    "# ----------------------------------------------\n",
    "common_genes = sorted(set(df_trans[\"gene_id\"]).intersection(df_meth[\"gene_id\"]))\n",
    "print(\"Common genes:\", len(common_genes))\n",
    "\n",
    "# Filter both to common genes only\n",
    "df_trans_f = df_trans[df_trans[\"gene_id\"].isin(common_genes)]\n",
    "df_meth_f  = df_meth[df_meth[\"gene_id\"].isin(common_genes)]\n",
    "\n",
    "# Set index to gene_id\n",
    "trans = df_trans_f.set_index(\"gene_id\")[common_samples]\n",
    "meth  = df_meth_f.set_index(\"gene_id\")[common_samples]\n",
    "\n",
    "# Now they match 1-to-1 without KeyError\n",
    "print(\"Transcriptomics aligned shape:\", trans.shape)\n",
    "print(\"Methylation aligned shape:\", meth.shape)\n",
    "\n",
    "# ----------------------------------------------\n",
    "# 5. Combined score\n",
    "# ----------------------------------------------\n",
    "combined = (1 - meth) * trans\n",
    "\n",
    "combined.to_csv(\"combined_epigenetic_score_matrix.csv\")\n",
    "\n",
    "print(\"Final combined shape:\", combined.shape)\n",
    "combined.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd31fc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed rows: 25\n",
      "Final shape: (19199, 89)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load combined matrix\n",
    "df = pd.read_csv(\"combined_epigenetic_score_matrix.csv\")\n",
    "\n",
    "# Remove Excel-destroyed \"date\" gene names\n",
    "bad_rows = df['gene_id'].str.contains(r'^\\d{1,2}[-/][A-Za-z]{3}$', regex=True, na=False)\n",
    "\n",
    "df_clean = df[~bad_rows]\n",
    "\n",
    "df_clean.to_csv(\"combined_epigenetic_score_matrix.csv\", index=False)\n",
    "\n",
    "print(\"Removed rows:\", bad_rows.sum())\n",
    "print(\"Final shape:\", df_clean.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5158a5",
   "metadata": {},
   "source": [
    "## Combine Pathology and Cohorts data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dc5844b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "merged_TCGA_Cohorts shape: (1779, 95)\n",
      "pathology_detail shape:   (175, 12)\n",
      "\n",
      "After merge shape: (3651, 106)\n",
      "\n",
      "Computing column statistics...\n",
      "\n",
      "Columns to drop (total 12):\n",
      "['demographic.age_is_obfuscated', 'diagnoses.ajcc_clinical_m', 'diagnoses.ajcc_pathologic_m', 'follow_ups.evidence_of_progression_type', 'follow_ups.evidence_of_recurrence_type', 'follow_ups.progression_or_recurrence', 'molecular_tests.biospecimen_type', 'molecular_tests.laboratory_test', 'molecular_tests.variant_type', 'pathology_details.consistent_pathology_review', 'treatments.chemo_concurrent_to_radiation', 'treatments.clinical_trial_indicator']\n",
      "\n",
      "Shape before clean: 3651 rows x 105 cols\n",
      "Shape after  clean: 3651 rows x 93 cols\n",
      "\n",
      "Drop report saved to: merged_clinical_pathology_drop_report.csv\n",
      "\n",
      "Curated dataset shape: (3651, 27)\n",
      "Curated columns included:\n",
      " - cases.case_id\n",
      " - cases.submitter_id\n",
      " - cases.primary_site\n",
      " - cases.disease_type\n",
      " - cases.index_date\n",
      " - cases.disease_index\n",
      " - demographic.age_at_index\n",
      " - demographic.gender\n",
      " - demographic.ethnicity\n",
      " - demographic.race\n",
      " - demographic.ethnicity_race\n",
      " - demographic.vital_status\n",
      " - demographic.days_to_death\n",
      " - diagnoses.age_at_diagnosis\n",
      " - diagnoses.primary_diagnosis\n",
      " - diagnoses.morphology\n",
      " - diagnoses.tumor_grade\n",
      " - diagnoses.days_to_last_follow_up\n",
      " - exposures.alcohol_history\n",
      " - exposures.pack_years_smoked\n",
      " - exposures.tobacco_smoking_status\n",
      " - pathology_details.margin_status\n",
      " - pathology_details.lymph_nodes_positive\n",
      " - pathology_details.lymph_nodes_tested\n",
      " - pathology_details.lymphatic_invasion_present\n",
      " - pathology_details.perineural_invasion_present\n",
      " - pathology_details.vascular_invasion_present\n",
      "\n",
      "Saved cleaned full dataset   -> merged_clinical_pathology_cleaned_full.csv\n",
      "Saved curated smaller dataset -> merged_clinical_pathology_curated_subset.csv\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# -----------------------------\n",
    "# CONFIG\n",
    "# -----------------------------\n",
    "MERGED_CLINICAL_PATH = \"merged_TCGA_Cohorts.csv\"\n",
    "PATHOLOGY_PATH = \"csv/pathology_detail.csv\"\n",
    "\n",
    "OUT_FULL_CLEAN = \"merged_clinical_pathology_cleaned_full.csv\"\n",
    "OUT_CURATED = \"merged_clinical_pathology_curated_subset.csv\"\n",
    "OUT_DROP_REPORT = \"merged_clinical_pathology_drop_report.csv\"\n",
    "\n",
    "# Thresholds for dropping\n",
    "MISSINGNESS_THRESHOLD = 0.95   # drop if >95% values are NaN\n",
    "LOW_VARIANCE_UNIQUE_MAX = 1    # drop if <= 1 unique non-null value\n",
    "\n",
    "# -----------------------------\n",
    "# 1. LOAD & MERGE\n",
    "# -----------------------------\n",
    "print(\"Loading data...\")\n",
    "merged = pd.read_csv(MERGED_CLINICAL_PATH)\n",
    "path = pd.read_csv(PATHOLOGY_PATH)\n",
    "\n",
    "print(f\"merged_TCGA_Cohorts shape: {merged.shape}\")\n",
    "print(f\"pathology_detail shape:   {path.shape}\")\n",
    "\n",
    "# Merge on cases.case_id (LEFT: keep all clinical cases)\n",
    "df = merged.merge(path, on=\"cases.case_id\", how=\"left\")\n",
    "print(f\"\\nAfter merge shape: {df.shape}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. UNIFY IDENTIFIERS\n",
    "# -----------------------------\n",
    "drop_reasons = {}  # column_name -> reason string\n",
    "\n",
    "# If both submitter_id versions exist and are identical, unify them\n",
    "if \"cases.submitter_id_x\" in df.columns and \"cases.submitter_id\" in df.columns:\n",
    "    same = (df[\"cases.submitter_id_x\"] == df[\"cases.submitter_id\"]) | \\\n",
    "           (df[\"cases.submitter_id\"].isna())\n",
    "    # Only assert if they're mostly identical; otherwise just prefer the clinical one\n",
    "    if same.mean() > 0.99:\n",
    "        # Use the clinical one (x) as the main submitter_id\n",
    "        df[\"cases.submitter_id\"] = df[\"cases.submitter_id_x\"]\n",
    "    # Drop the helper column\n",
    "    drop_reasons[\"cases.submitter_id_x\"] = \"manual_redundant: duplicate of cases.submitter_id\"\n",
    "    df.drop(columns=[\"cases.submitter_id_x\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. CREATE COMBINED / HELPER COLUMNS\n",
    "# -----------------------------\n",
    "# Combined disease_type + index_date, if both exist\n",
    "if \"cases.disease_type\" in df.columns and \"cases.index_date\" in df.columns:\n",
    "    if \"cases.disease_index\" not in df.columns:\n",
    "        df[\"cases.disease_index\"] = (\n",
    "            df[\"cases.disease_type\"].astype(str) + \" | \" +\n",
    "            df[\"cases.index_date\"].astype(str)\n",
    "        )\n",
    "\n",
    "# Combined race + ethnicity\n",
    "if \"demographic.ethnicity\" in df.columns and \"demographic.race\" in df.columns:\n",
    "    if \"demographic.ethnicity_race\" not in df.columns:\n",
    "        df[\"demographic.ethnicity_race\"] = (\n",
    "            df[\"demographic.ethnicity\"].astype(str) + \" | \" +\n",
    "            df[\"demographic.race\"].astype(str)\n",
    "        )\n",
    "\n",
    "# -----------------------------\n",
    "# 4. AUTOMATIC CLEANING (Option A)\n",
    "#    - All-null\n",
    "#    - High missingness\n",
    "#    - Low variance\n",
    "# -----------------------------\n",
    "print(\"\\nComputing column statistics...\")\n",
    "\n",
    "n_rows, n_cols = df.shape\n",
    "null_frac = df.isna().mean()\n",
    "nunique = df.nunique(dropna=True)\n",
    "\n",
    "cols_all_null = null_frac[null_frac == 1.0].index.tolist()\n",
    "cols_high_missing = null_frac[(null_frac > MISSINGNESS_THRESHOLD) &\n",
    "                              (null_frac < 1.0)].index.tolist()\n",
    "cols_low_variance = nunique[nunique <= LOW_VARIANCE_UNIQUE_MAX].index.tolist()\n",
    "\n",
    "# We don't want to drop key columns or obviously important ones, even if low variance\n",
    "force_keep = {\n",
    "    \"cases.case_id\",\n",
    "    \"cases.submitter_id\",\n",
    "    \"cases.primary_site\",\n",
    "    \"cases.disease_type\",\n",
    "    \"cases.index_date\",\n",
    "    \"cases.disease_index\",\n",
    "    \"demographic.age_at_index\",\n",
    "    \"demographic.gender\",\n",
    "    \"demographic.race\",\n",
    "    \"demographic.ethnicity\",\n",
    "    \"demographic.ethnicity_race\",\n",
    "    \"demographic.vital_status\",\n",
    "    \"demographic.days_to_death\",\n",
    "    \"diagnoses.age_at_diagnosis\",\n",
    "    \"diagnoses.primary_diagnosis\",\n",
    "    \"diagnoses.morphology\",\n",
    "    \"diagnoses.tumor_stage\",\n",
    "    \"diagnoses.tumor_grade\",\n",
    "    \"diagnoses.residual_disease\",\n",
    "    \"diagnoses.days_to_last_follow_up\",\n",
    "    \"diagnoses.progression_or_recurrence\",\n",
    "    \"exposures.pack_years_smoked\",\n",
    "    \"exposures.cigarettes_per_day\",\n",
    "    \"exposures.alcohol_history\",\n",
    "    \"exposures.tobacco_smoking_status\",\n",
    "    \"pathology_details.margin_status\",\n",
    "    \"pathology_details.lymph_nodes_positive\",\n",
    "    \"pathology_details.lymph_nodes_tested\",\n",
    "    \"pathology_details.lymphatic_invasion_present\",\n",
    "    \"pathology_details.perineural_invasion_present\",\n",
    "    \"pathology_details.vascular_invasion_present\",\n",
    "}\n",
    "\n",
    "# Ensure we only drop columns that are not forced to keep\n",
    "def filter_drop_list(cols, label):\n",
    "    filtered = []\n",
    "    for c in cols:\n",
    "        if c in force_keep:\n",
    "            continue\n",
    "        filtered.append(c)\n",
    "        # If a reason is not already assigned (manual), assign this one\n",
    "        if c not in drop_reasons:\n",
    "            drop_reasons[c] = f\"{label}\"\n",
    "    return filtered\n",
    "\n",
    "cols_all_null = filter_drop_list(cols_all_null, \"all_null\")\n",
    "cols_high_missing = filter_drop_list(cols_high_missing, \"high_missing\")\n",
    "cols_low_variance = filter_drop_list(cols_low_variance, \"low_variance\")\n",
    "\n",
    "# Combine all drop lists without duplication\n",
    "cols_to_drop = list(set(cols_all_null + cols_high_missing + cols_low_variance))\n",
    "\n",
    "print(f\"\\nColumns to drop (total {len(cols_to_drop)}):\")\n",
    "print(sorted(cols_to_drop))\n",
    "\n",
    "# Actually drop them\n",
    "df_clean = df.drop(columns=cols_to_drop, errors=\"ignore\")\n",
    "print(f\"\\nShape before clean: {n_rows} rows x {n_cols} cols\")\n",
    "print(f\"Shape after  clean: {df_clean.shape[0]} rows x {df_clean.shape[1]} cols\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5. BUILD DROP REPORT\n",
    "# -----------------------------\n",
    "# Build a dataframe with stats + reason for each dropped column\n",
    "rows = []\n",
    "for col in cols_to_drop:\n",
    "    rows.append({\n",
    "        \"column\": col,\n",
    "        \"reason\": drop_reasons.get(col, \"dropped\"),\n",
    "        \"null_fraction\": float(null_frac.get(col, float(\"nan\"))),\n",
    "        \"n_unique_non_null\": int(nunique.get(col, 0))\n",
    "    })\n",
    "\n",
    "drop_report_df = pd.DataFrame(rows).sort_values(\"column\")\n",
    "drop_report_df.to_csv(OUT_DROP_REPORT, index=False)\n",
    "print(f\"\\nDrop report saved to: {OUT_DROP_REPORT}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 6. BUILD CURATED, SMALLER DATASET\n",
    "#    (useful + related clinical & pathology columns)\n",
    "# -----------------------------\n",
    "curated_cols = [\n",
    "    # IDs\n",
    "    \"cases.case_id\",\n",
    "    \"cases.submitter_id\",\n",
    "    \"cases.primary_site\",\n",
    "    \"cases.disease_type\",\n",
    "    \"cases.index_date\",\n",
    "    \"cases.disease_index\",\n",
    "    # Demographics\n",
    "    \"demographic.age_at_index\",\n",
    "    \"demographic.gender\",\n",
    "    \"demographic.ethnicity\",\n",
    "    \"demographic.race\",\n",
    "    \"demographic.ethnicity_race\",\n",
    "    \"demographic.vital_status\",\n",
    "    \"demographic.days_to_death\",\n",
    "    # Diagnosis\n",
    "    \"diagnoses.age_at_diagnosis\",\n",
    "    \"diagnoses.primary_diagnosis\",\n",
    "    \"diagnoses.morphology\",\n",
    "    \"diagnoses.tumor_stage\",\n",
    "    \"diagnoses.tumor_grade\",\n",
    "    \"diagnoses.residual_disease\",\n",
    "    \"diagnoses.days_to_last_follow_up\",\n",
    "    \"diagnoses.progression_or_recurrence\",\n",
    "    # Exposures (far-but-related clinical context)\n",
    "    \"exposures.alcohol_history\",\n",
    "    \"exposures.pack_years_smoked\",\n",
    "    \"exposures.cigarettes_per_day\",\n",
    "    \"exposures.tobacco_smoking_status\",\n",
    "    # Pathology details\n",
    "    \"pathology_details.margin_status\",\n",
    "    \"pathology_details.lymph_nodes_positive\",\n",
    "    \"pathology_details.lymph_nodes_tested\",\n",
    "    \"pathology_details.lymphatic_invasion_present\",\n",
    "    \"pathology_details.perineural_invasion_present\",\n",
    "    \"pathology_details.vascular_invasion_present\",\n",
    "]\n",
    "\n",
    "# Keep only those that still exist after cleaning\n",
    "curated_cols_existing = [c for c in curated_cols if c in df_clean.columns]\n",
    "\n",
    "df_curated = df_clean[curated_cols_existing].copy()\n",
    "print(f\"\\nCurated dataset shape: {df_curated.shape}\")\n",
    "print(\"Curated columns included:\")\n",
    "for c in curated_cols_existing:\n",
    "    print(\" -\", c)\n",
    "\n",
    "# -----------------------------\n",
    "# 7. SAVE OUTPUTS\n",
    "# -----------------------------\n",
    "df_clean.to_csv(OUT_FULL_CLEAN, index=False)\n",
    "df_curated.to_csv(OUT_CURATED, index=False)\n",
    "\n",
    "print(f\"\\nSaved cleaned full dataset   -> {OUT_FULL_CLEAN}\")\n",
    "print(f\"Saved curated smaller dataset -> {OUT_CURATED}\")\n",
    "print(\"\\nDone.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd76090",
   "metadata": {},
   "source": [
    "## mutations.csv operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7159596c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with >90% null values: 105\n",
      "Dropped columns:\n",
      " ['dbSNP_Val_Status', 'UniProt_Site', 'UniProt_Natural_Variations', 'UniProt_Experimental_Info', 'COSMIC_overlapping_mutations', 'COSMIC_fusion_genes', 'DrugBank', 'CCLE_ONCOMAP_overlapping_mutations', 'CCLE_ONCOMAP_total_mutations_in_gene', 'CGC_Mutation_Type', 'CGC_Translocation_Partner', 'CGC_Tumor_Types_Somatic', 'CGC_Tumor_Types_Germline', 'CGC_Other_Diseases', 'DNARepairGenes_Role', 'FamilialCancerDatabase_Syndromes', 'MUTSIG_Published_Results', 'OREGANNO_ID', 'OREGANNO_Values', 'i_1000gp3_AA', 'i_1000gp3_AC', 'i_1000gp3_AF', 'i_1000gp3_AFR_AF', 'i_1000gp3_AMR_AF', 'i_1000gp3_AN', 'i_1000gp3_CIEND', 'i_1000gp3_CIPOS', 'i_1000gp3_DP', 'i_1000gp3_EAS_AF', 'i_1000gp3_EUR_AF', 'i_1000gp3_IMPRECISE', 'i_1000gp3_MEINFO', 'i_1000gp3_NS', 'i_1000gp3_SAS_AF', 'i_ACHILLES_Lineage_Results_Top_Genes', 'i_CCLE_ONCOMAP_overlapping_mutations', 'i_CCLE_ONCOMAP_total_mutations_in_gene', 'i_CGC_Cancer Germline Mut', 'i_CGC_Cancer Molecular Genetics', 'i_CGC_Cancer Somatic Mut', 'i_CGC_Cancer Syndrome', 'i_CGC_Chr', 'i_CGC_Chr Band', 'i_CGC_GeneID', 'i_CGC_Mutation_Type', 'i_CGC_Name', 'i_CGC_Other Germline Mut', 'i_CGC_Other_Diseases', 'i_CGC_Tissue Type', 'i_CGC_Translocation_Partner', 'i_CGC_Tumor_Types_Germline', 'i_CGC_Tumor_Types_Somatic', 'i_COSMIC_fusion_genes', 'i_COSMIC_overlapping_mutation_descriptions', 'i_COSMIC_overlapping_mutations', 'i_COSMIC_overlapping_primary_sites', 'i_ClinVar_ASSEMBLY', 'i_ClinVar_HGMD_ID', 'i_ClinVar_SYM', 'i_ClinVar_TYPE', 'i_ClinVar_rs', 'i_DNARepairGenes_Role', 'i_DrugBank', 'i_ESP_AA', 'i_ESP_AAC', 'i_ESP_AA_AC', 'i_ESP_AA_AGE', 'i_ESP_AA_GTC', 'i_ESP_CA', 'i_ESP_CDP', 'i_ESP_CG', 'i_ESP_CP', 'i_ESP_DBSNP', 'i_ESP_DP', 'i_ESP_EA_AC', 'i_ESP_EA_AGE', 'i_ESP_EA_GTC', 'i_ESP_EXOME_CHIP', 'i_ESP_FG', 'i_ESP_GL', 'i_ESP_GM', 'i_ESP_GS', 'i_ESP_GTC', 'i_ESP_GTS', 'i_ESP_MAF', 'i_ESP_PH', 'i_ESP_PP', 'i_ESP_TAC', 'i_FamilialCancerDatabase_Syndromes', 'i_Familial_Cancer_Genes_Reference', 'i_Familial_Cancer_Genes_Synonym', 'i_HGNC_Enzyme IDs', 'i_MUTSIG_Published_Results', 'i_OREGANNO_ID', 'i_OREGANNO_Values', 'i_ORegAnno_bin', 'i_UniProt_Experimental_Info', 'i_UniProt_Natural_Variations', 'i_UniProt_Site', 'i_entrez_gene_id', 'i_secondary_variant_classification', 'validation_alt_allele', 'validation_method', 'validation_status', 'validation_tumor_sample']\n",
      "Original shape: (13180, 325)\n",
      "Cleaned shape:  (13180, 220)\n",
      "\n",
      "Saved cleaned dataset as mutations_cleaned.csv!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"mutations.csv\", low_memory=False)\n",
    "\n",
    "# 1. Calculate null ratio for each column\n",
    "null_ratio = df.isna().mean()\n",
    "\n",
    "# 2. Identify columns with >90% null values\n",
    "cols_to_drop = null_ratio[null_ratio > 0.90].index.tolist()\n",
    "\n",
    "print(f\"Columns with >90% null values: {len(cols_to_drop)}\")\n",
    "print(\"Dropped columns:\\n\", cols_to_drop)\n",
    "\n",
    "# 3. Drop these columns\n",
    "clean_df = df.drop(columns=cols_to_drop)\n",
    "\n",
    "print(f\"Original shape: {df.shape}\")\n",
    "print(f\"Cleaned shape:  {clean_df.shape}\")\n",
    "\n",
    "# 4. Save cleaned version\n",
    "clean_df.to_csv(\"mutations_cleaned.csv\", index=False)\n",
    "\n",
    "print(\"\\nSaved cleaned dataset as mutations_cleaned.csv!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b1e7441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dropping manually identified columns: 4\n",
      "['Center', 'NCBI_Build', 'Strand', 'Sequencer']\n",
      "\n",
      "Dropping columns with >50% null: 15\n",
      "['dbSNP_RS', 'UniProt_Region', 'Tumorscape_Amplification_Peaks', 'Tumorscape_Deletion_Peaks', 'TCGAscape_Amplification_Peaks', 'TCGAscape_Deletion_Peaks', 'i_HGNC_Date Name Changed', 'i_HGNC_Date Symbol Changed', 'i_HGNC_Name Synonyms', 'i_HGNC_Previous Names', 'i_HGNC_Previous Symbols', 'i_TCGAscape_Amplification_Peaks', 'i_TCGAscape_Deletion_Peaks', 'i_Tumorscape_Amplification_Peaks', 'i_Tumorscape_Deletion_Peaks']\n",
      "\n",
      "Done! Saved as mutations_final_clean.csv\n",
      "Final shape: (13180, 201)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"mutations_cleaned.csv\", low_memory=False)\n",
    "\n",
    "# -----------------------------------------------\n",
    "# 1. Define unnecessary columns to remove manually\n",
    "# -----------------------------------------------\n",
    "drop_cols_manual = [\n",
    "    \"Center\", \"NCBI_Build\", \"Strand\", \"Sequencer\",\n",
    "    \"Match_Norm_Seq_Allele1\", \"Match_Norm_Seq_Allele2\",\n",
    "    \"Match_Norm_Validation_Allele1\", \"Match_Norm_Validation_Allele2\",\n",
    "    \"Match_Norm_Validation_Method\", \"Match_Norm_Validation_Status\",\n",
    "    \"Match_Norm_Sample_Barcode\",\n",
    "\n",
    "    # Full-depth counts that duplicate alt/ref counts\n",
    "    \"t_depth_full\", \"t_alt_count_full\", \"t_ref_count_full\",\n",
    "    \"n_depth_full\", \"n_alt_count_full\", \"n_ref_count_full\",\n",
    "\n",
    "    # Overlapping annotations rarely used\n",
    "    \"COSMIC_overlapping_mutations\", \"COSMIC_fusion_genes\",\n",
    "    \"ExAC_AF\", \"ExAC_FILTER\", \"ExAC_qt\",\n",
    "\n",
    "    # Predictors with sparse values\n",
    "    \"SIFT\", \"PolyPhen\", \"PROVEAN\", \"CLIN_SIG\"\n",
    "]\n",
    "\n",
    "# Keep only columns that exist in the df\n",
    "drop_cols_manual = [c for c in drop_cols_manual if c in df.columns]\n",
    "\n",
    "print(\"\\nDropping manually identified columns:\", len(drop_cols_manual))\n",
    "print(drop_cols_manual)\n",
    "\n",
    "df = df.drop(columns=drop_cols_manual)\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 2. Automatic cleanup: Drop columns >50% null\n",
    "# ------------------------------------------------\n",
    "null_ratio = df.isna().mean()\n",
    "auto_drop = null_ratio[null_ratio > 0.5].index.tolist()\n",
    "\n",
    "print(\"\\nDropping columns with >50% null:\", len(auto_drop))\n",
    "print(auto_drop)\n",
    "\n",
    "df = df.drop(columns=auto_drop)\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 3. Save clean dataset\n",
    "# ------------------------------------------------\n",
    "df.to_csv(\"mutations_final_clean.csv\", index=False)\n",
    "\n",
    "print(\"\\nDone! Saved as mutations_final_clean.csv\")\n",
    "print(\"Final shape:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6872e2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (13180, 325)\n",
      "\n",
      "Dropping columns with >90% null values: 105\n",
      "Shape after >90% null drop: (13180, 220)\n",
      "\n",
      "Filtered functional Variant_Classification:\n",
      "  Rows before: 13180\n",
      "  Rows after:  9637\n",
      "\n",
      "Computed VAF = t_alt_count / (t_alt_count + t_ref_count)\n",
      "\n",
      "Essential columns requested: 18\n",
      "Columns found and kept:       14\n",
      "Kept columns: ['Hugo_Symbol', 'Entrez_Gene_Id', 'Chromosome', 'Start_position', 'End_position', 'Reference_Allele', 'Tumor_Seq_Allele1', 'Tumor_Seq_Allele2', 'Variant_Classification', 'Variant_Type', 'Tumor_Sample_Barcode', 't_alt_count', 't_ref_count', 'VAF']\n",
      "Missing (not in file): ['HGVSc', 'HGVSp_Short', 'n_alt_count', 'n_ref_count']\n",
      "\n",
      "Final reduced shape: (9637, 14)\n",
      "\n",
      "Saved reduced dataset to: mutations_reduced.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ---------- 1. Load original file ----------\n",
    "input_path = \"mutations.csv\"        # change this to your local path if needed\n",
    "df = pd.read_csv(input_path, low_memory=False)\n",
    "\n",
    "print(\"Original shape:\", df.shape)\n",
    "\n",
    "# ---------- 2. Drop columns with >90% null ----------\n",
    "null_ratio = df.isna().mean()\n",
    "cols_drop_null90 = null_ratio[null_ratio > 0.90].index.tolist()\n",
    "\n",
    "print(f\"\\nDropping columns with >90% null values: {len(cols_drop_null90)}\")\n",
    "df = df.drop(columns=cols_drop_null90)\n",
    "print(\"Shape after >90% null drop:\", df.shape)\n",
    "\n",
    "# ---------- 3. Keep only FUNCTIONAL (non-synonymous) mutations ----------\n",
    "\n",
    "# Variant_Classification values to KEEP\n",
    "functional_classes = [\n",
    "    \"Missense_Mutation\",\n",
    "    \"Nonsense_Mutation\",\n",
    "    \"Frame_Shift_Del\",\n",
    "    \"Frame_Shift_Ins\",\n",
    "    \"In_Frame_Del\",\n",
    "    \"In_Frame_Ins\",\n",
    "    \"Splice_Site\",\n",
    "    \"Translation_Start_Site\",\n",
    "    \"Nonstop_Mutation\"\n",
    "]\n",
    "\n",
    "if \"Variant_Classification\" in df.columns:\n",
    "    before_rows = df.shape[0]\n",
    "    df = df[df[\"Variant_Classification\"].isin(functional_classes)]\n",
    "    after_rows = df.shape[0]\n",
    "    print(f\"\\nFiltered functional Variant_Classification:\")\n",
    "    print(f\"  Rows before: {before_rows}\")\n",
    "    print(f\"  Rows after:  {after_rows}\")\n",
    "else:\n",
    "    print(\"\\n 'Variant_Classification' not found - skipping functional filter.\")\n",
    "\n",
    "# ---------- 4. Compute Variant Allele Frequency (VAF) ----------\n",
    "\n",
    "if {\"t_alt_count\", \"t_ref_count\"}.issubset(df.columns):\n",
    "    depth = df[\"t_alt_count\"] + df[\"t_ref_count\"]\n",
    "    df[\"VAF\"] = np.where(depth > 0, df[\"t_alt_count\"] / depth, np.nan)\n",
    "    print(\"\\nComputed VAF = t_alt_count / (t_alt_count + t_ref_count)\")\n",
    "else:\n",
    "    print(\"\\n t_alt_count and/or t_ref_count columns not found - skipping VAF.\")\n",
    "\n",
    "# ---------- 5. Keep only essential columns ----------\n",
    "\n",
    "essential_cols = [\n",
    "    \"Hugo_Symbol\",\n",
    "    \"Entrez_Gene_Id\",\n",
    "    \"Chromosome\",\n",
    "    \"Start_position\",\n",
    "    \"End_position\",\n",
    "    \"Reference_Allele\",\n",
    "    \"Tumor_Seq_Allele1\",\n",
    "    \"Tumor_Seq_Allele2\",\n",
    "    \"Variant_Classification\",\n",
    "    \"Variant_Type\",\n",
    "    \"Tumor_Sample_Barcode\",\n",
    "    \"HGVSc\",\n",
    "    \"HGVSp_Short\",\n",
    "    \"t_alt_count\",\n",
    "    \"t_ref_count\",\n",
    "    \"n_alt_count\",\n",
    "    \"n_ref_count\",\n",
    "    \"VAF\"\n",
    "]\n",
    "\n",
    "existing_cols = [c for c in essential_cols if c in df.columns]\n",
    "missing_cols = [c for c in essential_cols if c not in df.columns]\n",
    "\n",
    "print(f\"\\nEssential columns requested: {len(essential_cols)}\")\n",
    "print(f\"Columns found and kept:       {len(existing_cols)}\")\n",
    "print(\"Kept columns:\", existing_cols)\n",
    "if missing_cols:\n",
    "    print(\"Missing (not in file):\", missing_cols)\n",
    "\n",
    "df_reduced = df[existing_cols].copy()\n",
    "\n",
    "print(\"\\nFinal reduced shape:\", df_reduced.shape)\n",
    "\n",
    "# ---------- 6. Save reduced dataset ----------\n",
    "output_path = \"mutations_reduced.csv\"   # change if you want another name/path\n",
    "df_reduced.to_csv(output_path, index=False)\n",
    "print(f\"\\nSaved reduced dataset to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "404eab1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded:\n",
      "  mutations:    (9637, 14)\n",
      "  pathology:    (3651, 93)\n",
      "  epigenetics:  (19199, 89)\n",
      "\n",
      "[INFO] mutation columns: ['Hugo_Symbol', 'Entrez_Gene_Id', 'Chromosome', 'Start_position', 'End_position', 'Reference_Allele', 'Tumor_Seq_Allele1', 'Tumor_Seq_Allele2', 'Variant_Classification', 'Variant_Type', 'Tumor_Sample_Barcode', 't_alt_count', 't_ref_count', 'VAF']\n",
      "[INFO] pathology columns: ['cases.case_id', 'cases.consent_type', 'cases.days_to_consent', 'cases.disease_type', 'cases.index_date', 'cases.lost_to_followup', 'cases.primary_site', 'demographic.age_at_index', 'demographic.cause_of_death', 'demographic.country_of_residence_at_enrollment'] ...\n",
      "[INFO] epigenetic columns: ['gene_id', 'TCGA-BA-4074-01', 'TCGA-BA-4077-01', 'TCGA-BA-5153-01', 'TCGA-BA-5556-01', 'TCGA-BA-5557-01', 'TCGA-BA-6872-01', 'TCGA-BA-6873-01', 'TCGA-BA-7269-01', 'TCGA-BB-4224-01'] ...\n",
      "\n",
      "[INFO] Example mutation Sample_ID_15: ['TCGA-BA-4074-01', 'TCGA-BA-4074-01', 'TCGA-BA-4074-01', 'TCGA-BA-4074-01', 'TCGA-BA-4074-01']\n",
      "[INFO] Example mutation Case_ID_12: ['TCGA-BA-4074', 'TCGA-BA-4074', 'TCGA-BA-4074', 'TCGA-BA-4074', 'TCGA-BA-4074']\n",
      "[INFO] Example epi columns: ['TCGA-BA-4074-01', 'TCGA-BA-4077-01', 'TCGA-BA-5153-01', 'TCGA-BA-5556-01', 'TCGA-BA-5557-01', 'TCGA-BA-6872-01', 'TCGA-BA-6873-01', 'TCGA-BA-7269-01', 'TCGA-BB-4224-01', 'TCGA-BB-4225-01']\n",
      "\n",
      "=== Building mutations_plus_pathology.csv ===\n",
      "Merged mutations + pathology shape: (401115, 109)\n",
      "Saved: mutations_plus_pathology.csv\n",
      "\n",
      "=== Building mutations_plus_epigenetics.csv ===\n",
      "Initial mutation matrix shape (genes x samples): (6218, 82)\n",
      "Number of common genes between mutation & epigenetic: 5594\n",
      "mut_mat_common shape: (5594, 82)\n",
      "epi_common shape: (5594, 88)\n",
      "Final mutations_plus_epigenetics shape: (5594, 170)\n",
      "Saved: mutations_plus_epigenetics.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ======================================================\n",
    "# 0. FILE PATHS (EDIT IF NEEDED)\n",
    "# ======================================================\n",
    "\n",
    "mut_path = \"mutations_reduced.csv\"\n",
    "pathology_path = \"Pathology_Cohorts.csv\"\n",
    "epigenetic_path = \"combined_epigenetic_score_matrix.csv\"\n",
    "\n",
    "# ======================================================\n",
    "# 1. LOAD DATASETS\n",
    "# ======================================================\n",
    "\n",
    "mut = pd.read_csv(mut_path, low_memory=False)\n",
    "path = pd.read_csv(pathology_path, low_memory=False)\n",
    "epi = pd.read_csv(epigenetic_path, low_memory=False)\n",
    "\n",
    "print(\"Loaded:\")\n",
    "print(\"  mutations:   \", mut.shape)\n",
    "print(\"  pathology:   \", path.shape)\n",
    "print(\"  epigenetics: \", epi.shape)\n",
    "\n",
    "# Quick sanity check for key columns\n",
    "print(\"\\n[INFO] mutation columns:\", mut.columns.tolist())\n",
    "print(\"[INFO] pathology columns:\", path.columns.tolist()[:10], \"...\")  # first 10\n",
    "print(\"[INFO] epigenetic columns:\", epi.columns.tolist()[:10], \"...\")\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 2. STANDARDISE BARCODES\n",
    "# ======================================================\n",
    "# TCGA barcode levels:\n",
    "# - Case (patient):   TCGA-BA-4074         (12 chars)\n",
    "# - Sample:           TCGA-BA-4074-01      (15 chars)\n",
    "# - Full aliquot:     TCGA-BA-4074-01A-... (long)\n",
    "\n",
    "# -------- 2.1 From mutation data --------\n",
    "if \"Tumor_Sample_Barcode\" not in mut.columns:\n",
    "    raise KeyError(\"Tumor_Sample_Barcode not found in mutations_reduced.csv\")\n",
    "\n",
    "# Sample-level ID for epigenetic merge (first 15 chars)\n",
    "mut[\"Sample_ID_15\"] = mut[\"Tumor_Sample_Barcode\"].astype(str).str[:15]\n",
    "\n",
    "# Case-level ID for pathology merge (first 12 chars)\n",
    "mut[\"Case_ID_12\"] = mut[\"Tumor_Sample_Barcode\"].astype(str).str[:12]\n",
    "\n",
    "\n",
    "# -------- 2.2 From pathology data --------\n",
    "if \"cases.submitter_id\" not in path.columns:\n",
    "    raise KeyError(\"cases.submitter_id not found in Pathology_Cohorts.csv\")\n",
    "\n",
    "path[\"Case_ID_12\"] = path[\"cases.submitter_id\"].astype(str).str[:12]\n",
    "\n",
    "\n",
    "# -------- 2.3 From epigenetic data --------\n",
    "# Assume: first column = gene name, remaining columns = TCGA sample barcodes.\n",
    "epi_gene_col = epi.columns[0]\n",
    "epi = epi.rename(columns={epi_gene_col: \"Gene\"})\n",
    "epi.set_index(\"Gene\", inplace=True)\n",
    "\n",
    "# Epigenetic columns should already look like TCGA-XX-XXXX-01\n",
    "# If any have longer suffixes, truncate to first 15 chars\n",
    "epi_cols_renamed = {}\n",
    "for col in epi.columns:\n",
    "    if col.startswith(\"TCGA\"):\n",
    "        epi_cols_renamed[col] = col[:15]\n",
    "epi.rename(columns=epi_cols_renamed, inplace=True)\n",
    "\n",
    "print(\"\\n[INFO] Example mutation Sample_ID_15:\", mut[\"Sample_ID_15\"].head().tolist())\n",
    "print(\"[INFO] Example mutation Case_ID_12:\", mut[\"Case_ID_12\"].head().tolist())\n",
    "print(\"[INFO] Example epi columns:\", epi.columns[:10].tolist())\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 3. FILE 1  MERGE MUTATIONS WITH PATHOLOGY\n",
    "# ======================================================\n",
    "\n",
    "print(\"\\n=== Building mutations_plus_pathology.csv ===\")\n",
    "\n",
    "# We'll keep all mutation columns + all pathology columns\n",
    "mut_plus_path = mut.merge(\n",
    "    path,\n",
    "    on=\"Case_ID_12\",\n",
    "    how=\"inner\",  # only patients present in both\n",
    "    suffixes=(\"_mut\", \"_path\")\n",
    ")\n",
    "\n",
    "print(\"Merged mutations + pathology shape:\", mut_plus_path.shape)\n",
    "\n",
    "mut_plus_path.to_csv(\"mutations_plus_pathology.csv\", index=False)\n",
    "print(\"Saved: mutations_plus_pathology.csv\")\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 4. FILE 2  BUILD MUTATION MATRIX + MERGE WITH EPIGENETIC MATRIX\n",
    "# ======================================================\n",
    "\n",
    "print(\"\\n=== Building mutations_plus_epigenetics.csv ===\")\n",
    "\n",
    "# 4.1 Build a gene  sample mutation matrix (binary 0/1)\n",
    "# One row per gene, one column per sample (Sample_ID_15)\n",
    "if not {\"Hugo_Symbol\", \"Sample_ID_15\"}.issubset(mut.columns):\n",
    "    raise KeyError(\"Hugo_Symbol and/or Sample_ID_15 missing in mutation data.\")\n",
    "\n",
    "mutation_matrix = (\n",
    "    mut\n",
    "    .groupby([\"Hugo_Symbol\", \"Sample_ID_15\"])\n",
    "    .size()\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "\n",
    "print(\"Initial mutation matrix shape (genes x samples):\", mutation_matrix.shape)\n",
    "\n",
    "# Optional: convert counts >0 to 1 (pure binary mutated/not mutated)\n",
    "mutation_matrix = (mutation_matrix > 0).astype(int)\n",
    "\n",
    "\n",
    "# 4.2 Align genes between mutation matrix and epigenetic matrix\n",
    "common_genes = mutation_matrix.index.intersection(epi.index)\n",
    "print(\"Number of common genes between mutation & epigenetic:\", len(common_genes))\n",
    "\n",
    "mut_mat_common = mutation_matrix.loc[common_genes]\n",
    "epi_common = epi.loc[common_genes]\n",
    "\n",
    "print(\"mut_mat_common shape:\", mut_mat_common.shape)\n",
    "print(\"epi_common shape:\", epi_common.shape)\n",
    "\n",
    "# 4.3 Concatenate along columns: for each gene,\n",
    "# [mutation features (samples)] + [epigenetic features (samples)]\n",
    "mut_plus_epi = pd.concat([mut_mat_common, epi_common], axis=1)\n",
    "\n",
    "print(\"Final mutations_plus_epigenetics shape:\", mut_plus_epi.shape)\n",
    "\n",
    "mut_plus_epi.to_csv(\"mutations_plus_epigenetics.csv\")\n",
    "print(\"Saved: mutations_plus_epigenetics.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "335346fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Intersection sample count: 82\n",
      "Common samples: ['TCGA-BA-4074-01', 'TCGA-BA-4077-01', 'TCGA-BA-5153-01', 'TCGA-BA-5556-01', 'TCGA-BA-5557-01', 'TCGA-BA-6872-01', 'TCGA-BA-6873-01', 'TCGA-BA-7269-01', 'TCGA-BB-4224-01', 'TCGA-BB-4225-01', 'TCGA-BB-4228-01', 'TCGA-CN-4726-01', 'TCGA-CN-4729-01', 'TCGA-CN-4737-01', 'TCGA-CN-4740-01', 'TCGA-CN-4741-01', 'TCGA-CN-4742-01', 'TCGA-CN-5359-01', 'TCGA-CN-5364-01', 'TCGA-CN-6016-01', 'TCGA-CN-6018-01', 'TCGA-CN-6995-01', 'TCGA-CQ-5330-01', 'TCGA-CQ-5331-01', 'TCGA-CQ-5332-01', 'TCGA-CQ-5334-01', 'TCGA-CQ-7065-01', 'TCGA-CQ-7068-01', 'TCGA-CR-6477-01', 'TCGA-CR-6478-01', 'TCGA-CR-6481-01', 'TCGA-CR-6487-01', 'TCGA-CR-6488-01', 'TCGA-CR-6493-01', 'TCGA-CR-7367-01', 'TCGA-CR-7368-01', 'TCGA-CR-7372-01', 'TCGA-CR-7373-01', 'TCGA-CR-7376-01', 'TCGA-CR-7379-01', 'TCGA-CR-7383-01', 'TCGA-CR-7385-01', 'TCGA-CR-7391-01', 'TCGA-CR-7392-01', 'TCGA-CR-7394-01', 'TCGA-CR-7401-01', 'TCGA-CV-5442-01', 'TCGA-CV-5971-01', 'TCGA-CV-5973-01', 'TCGA-CV-5979-01', 'TCGA-CV-6433-01', 'TCGA-CV-6441-01', 'TCGA-CV-6934-01', 'TCGA-CV-6945-01', 'TCGA-CV-6948-01', 'TCGA-CV-6956-01', 'TCGA-CV-6959-01', 'TCGA-CV-7097-01', 'TCGA-CV-7099-01', 'TCGA-CV-7100-01', 'TCGA-CV-7102-01', 'TCGA-CV-7103-01', 'TCGA-CV-7183-01', 'TCGA-CV-7235-01', 'TCGA-CV-7236-01', 'TCGA-CV-7238-01', 'TCGA-CV-7255-01', 'TCGA-CV-7263-01', 'TCGA-CV-7411-01', 'TCGA-CV-7413-01', 'TCGA-CV-7416-01', 'TCGA-CV-7434-01', 'TCGA-CX-7082-01', 'TCGA-CX-7086-01', 'TCGA-D6-6516-01', 'TCGA-D6-6823-01', 'TCGA-DQ-5624-01', 'TCGA-DQ-5625-01', 'TCGA-DQ-5631-01', 'TCGA-DQ-7588-01', 'TCGA-H7-7774-01', 'TCGA-HD-7831-01']\n",
      "\n",
      "Saved: mutation_epigenetic_interaction_matrix.csv\n",
      "Final shape: (5594, 82)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your multi-omics file\n",
    "df = pd.read_csv(\"mutations_plus_epigenetics.csv\", index_col=0)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. Identify mutation and epigenetic columns\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "mut_cols = df.columns[:82]     # first 82 = mutation block\n",
    "epi_cols = df.columns[82:]     # last 88 = epigenetic block\n",
    "\n",
    "df_mut = df[mut_cols].copy()\n",
    "df_epi = df[epi_cols].copy()\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. Clean epigenetic column names (remove .1)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "clean_epi_cols = []\n",
    "\n",
    "for c in df_epi.columns:\n",
    "    if c.endswith(\".1\"):\n",
    "        clean_epi_cols.append(c[:-2])   # remove \".1\"\n",
    "    else:\n",
    "        clean_epi_cols.append(c)\n",
    "\n",
    "df_epi.columns = clean_epi_cols\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. Remove -11 samples (normal tissue, not tumour)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "df_epi = df_epi[[c for c in df_epi.columns if not c.endswith(\"-11\")]]\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. Find intersection\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "mutation_samples = set(df_mut.columns)\n",
    "epigenetic_samples = set(df_epi.columns)\n",
    "\n",
    "common_samples = sorted(list(mutation_samples & epigenetic_samples))\n",
    "\n",
    "print(\"\\nIntersection sample count:\", len(common_samples))\n",
    "print(\"Common samples:\", common_samples)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 5. Multiply mutation  epigenetic values\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "interaction_df = df_mut[common_samples] * df_epi[common_samples]\n",
    "\n",
    "interaction_df.to_csv(\"mutation_epigenetic_interaction_matrix.csv\")\n",
    "\n",
    "print(\"\\nSaved: mutation_epigenetic_interaction_matrix.csv\")\n",
    "print(\"Final shape:\", interaction_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7828c85",
   "metadata": {},
   "source": [
    "## Add tag to Pathology_Cohort.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efe52a9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pathology_Cohorts_UPDATED_firstcol.csv'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load files\n",
    "clinical = pd.read_csv(\"clinical.csv\")\n",
    "patho = pd.read_csv(\"Pathology_Cohorts.csv\")\n",
    "\n",
    "# Extract mapping\n",
    "clinical_map = clinical[[\"cases.case_id\", \"cases.submitter_id\"]].drop_duplicates()\n",
    "\n",
    "# Merge\n",
    "updated = patho.merge(clinical_map, on=\"cases.case_id\", how=\"left\", suffixes=(\"\", \"_from_clinical\"))\n",
    "\n",
    "# Fill or create submitter_id\n",
    "if \"cases.submitter_id\" in updated.columns:\n",
    "    updated[\"cases.submitter_id\"] = updated[\"cases.submitter_id\"].fillna(updated[\"cases.submitter_id_from_clinical\"])\n",
    "else:\n",
    "    updated.rename(columns={\"cases.submitter_id_from_clinical\": \"cases.submitter_id\"}, inplace=True)\n",
    "\n",
    "# Drop helper column\n",
    "if \"cases.submitter_id_from_clinical\" in updated.columns:\n",
    "    updated.drop(columns=[\"cases.submitter_id_from_clinical\"], inplace=True)\n",
    "\n",
    "# Make cases.submitter_id the first column\n",
    "cols = [\"cases.submitter_id\"] + [c for c in updated.columns if c != \"cases.submitter_id\"]\n",
    "updated = updated[cols]\n",
    "\n",
    "# Save updated file\n",
    "output = \"Pathology_Cohorts_UPDATED_firstcol.csv\"\n",
    "updated.to_csv(output, index=False)\n",
    "\n",
    "output\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
